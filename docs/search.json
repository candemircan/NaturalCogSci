[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Read Me!",
    "section": "",
    "text": "Code for the project “Language Aligned Visual Representations Predict Human Behavior in Naturalistic Learning Tasks”\nPlease see the paper for the associated work."
  },
  {
    "objectID": "index.html#setup",
    "href": "index.html#setup",
    "title": "Read Me!",
    "section": "Setup",
    "text": "Setup\nI ran the analyses on a cluster system that used a SLURM job scheduler and a singularity image. Therefore the bash and slurm scripts are specific to that system. However, the singularity image is available on dockerhub and can be run locally using the following command:\ndocker pull candemircan/naturalcogsci:latest\nIf you want to use the singularity image, you can pull it as follows\nsingularity pull NaturalCogSci.sif docker://candemircan/naturalcogsci:latest\nIf you do not want to use containers, you can install the Python dependencies as follows:\ngit clone https://github.com/candemircan/NaturalCogSci.git\ncd NaturalCogSci\npip install -r requirements.txt\npip install -e .\nFor the versions of R dependencies, you can see the DOCKERFILE"
  },
  {
    "objectID": "index.html#environment-variables",
    "href": "index.html#environment-variables",
    "title": "Read Me!",
    "section": "Environment Variables",
    "text": "Environment Variables\nThe code uses the environment variable NATURALCOGSCI_ROOT to determine the root directory of the project. You can set this variable in your .bashrc file (or whatever your shell rc file might be) as follows:\nexport NATURALCOGSCI_ROOT=/path/to/NaturalCogSci\nFor me, R could not read this variable from the shell, so I had to set it in the ~/.Renviron file as well as follows:\nNATURALCOGSCI_ROOT=/path/to/NaturalCogSci"
  },
  {
    "objectID": "index.html#experiments",
    "href": "index.html#experiments",
    "title": "Read Me!",
    "section": "Experiments",
    "text": "Experiments\nBoth experiments are shared under the experiments folder. See the README.md files in the respective folders for more information."
  },
  {
    "objectID": "index.html#stimuli",
    "href": "index.html#stimuli",
    "title": "Read Me!",
    "section": "Stimuli",
    "text": "Stimuli\nIf you want to extract the features from the images , you need to download the THINGS database under the stimuli folder.\nThis can be done from the following link:\nhttps://things-initiative.org/uploads/THINGS/images.zip"
  },
  {
    "objectID": "index.html#data",
    "href": "index.html#data",
    "title": "Read Me!",
    "section": "Data",
    "text": "Data\nThe data is shared in an OSF repository. It should be put under the data folder, if you want to use the code as is. All the behavioural (anaonymised) and modelling data can be found in the OSF repo. Further detail about the data are found under the README.md file in the data folder.\nThe OSF repository is here: https://osf.io/h3t52/"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Read Me!",
    "section": "Citation",
    "text": "Citation\nIf you use our work, please cite our paper as such:\n@misc{demircan2023language,\n      title={Language Aligned Visual Representations Predict Human Behavior in Naturalistic Learning Tasks}, \n      author={Can Demircan and Tankred Saanum and Leonardo Pettini and Marcel Binz and Blazej M Baczkowski and Paula Kaanders and Christian F Doeller and Mona M Garvert and Eric Schulz},\n      year={2023},\n      eprint={2306.09377},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}"
  },
  {
    "objectID": "feature_extractors.html",
    "href": "feature_extractors.html",
    "title": "Feature Extraction Functions",
    "section": "",
    "text": "Functions to extract features from DNNs.\n\nExtracts features for all images written under file_names.txt in the data folder, which are all the images in the THINGS database.\nYou must also have the THINGS images under the stimuli folder in the project root.\n\n\nimport glob\nimport os\nfrom os.path import join\nfrom shutil import rmtree\nimport json\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport fasttext\nfrom transformers import AutoTokenizer, AutoModel\nfrom thingsvision import get_extractor, get_extractor_from_model\nfrom thingsvision.utils.data import ImageDataset, DataLoader\nimport tensorflow_hub as hub\nimport openai\nfrom harmonization.models import (\n    load_ViT_B16,\n    load_ResNet50,\n    load_VGG16,\n    load_EfficientNetB0,\n    load_tiny_ConvNeXT,\n    load_tiny_MaxViT,\n    load_LeViT_small,\n)\n\n\nfrom NaturalCogSci.helpers import get_project_root\n\n\n\nCode\ndef extract_features(feature_name: str,  # same as model name. In case different encoders are available, it is in `model_encoder` format\n                     use_cached: bool = True # If `True`, rerun extraction even if the features are saved. Defaults to True.\n                     )-&gt; np.ndarray: # feature array\n    \"\"\"\n    Extract features from a model and save to disk.\n    \"\"\"\n    project_root = get_project_root()\n    temp_feature_path = join(project_root, \"data\", \"temp\", f\"{feature_name}\")\n    final_feature_path = join(project_root,\"data\",\"features\",f\"{feature_name.replace('/', '_')}.txt\")\n\n    hugging_face_dict = {\n        \"distilbert\": \"distilbert-base-uncased\",\n        \"bert\": \"bert-base-uncased\",\n        \"roberta\": \"roberta-base\",\n    }\n\n\n    if os.path.exists(final_feature_path) and use_cached:\n        return None\n\n    if feature_name == \"task\":\n        objects = folder_to_word(remove_digit_underscore=False)\n        ids = pd.read_csv(join(project_root, \"data\", \"THINGS\", \"unique_id.csv\"))[\n            \"id\"\n        ].to_list()\n        weights = np.loadtxt(\n            join(project_root, \"data\", \"THINGS\", \"spose_embedding_49d_sorted.txt\")\n        )\n\n        features = [weights[ids.index(obj), :] for obj in objects]\n        features = np.array(features)\n    \n    elif feature_name == \"ada-002\":\n\n        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n        objects = folder_to_word(remove_digit_underscore=True)\n        objects = [f\"A photo of a {x}\" for x in objects]\n        features = np.array([get_ada_embedding(obj) for obj in objects])\n\n\n    elif feature_name in [\"bert\", \"roberta\"]:\n        objects = folder_to_word(remove_digit_underscore=True)\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        tokenizer = AutoTokenizer.from_pretrained(hugging_face_dict[feature_name])\n        model = AutoModel.from_pretrained(hugging_face_dict[feature_name]).to(device)\n        objects = [f\"A photo of a {x}\" for x in objects]\n\n        tokenized_objects = tokenizer(\n            objects, padding=True, truncation=True, return_tensors=\"pt\"\n        )\n        tokenized_objects = {\n            k: torch.tensor(v).to(device) for k, v in tokenized_objects.items()\n        }\n\n        with torch.no_grad():\n            latent_objects = model(**tokenized_objects)\n\n        features = latent_objects.last_hidden_state[:, 0, :].numpy()\n\n    elif feature_name == \"fasttext\":\n        objects = folder_to_word(remove_digit_underscore=True)\n        ft = fasttext.load_model(\n            join(project_root, \"data\", \"embedding_weights_and_binaries\", \"crawl-300d-2M-subword.bin\")\n        )\n        features = [ft.get_word_vector(x) for x in objects]\n        features = np.array(features)\n    elif feature_name == \"universal_sentence_encoder\":\n        objects = folder_to_word(remove_digit_underscore=True)\n        objects = [f\"A photo of a {x}\" for x in objects]\n        module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n        model = hub.load(module_url)\n        features = model(objects).numpy()\n    else:\n        features = get_visual_embedding(project_root, feature_name)\n\n\n    feature_name = feature_name.replace(\"/\", \"_\") \n    np.savetxt(\n        final_feature_path, features\n    )\n\n    return None\n\n\n\nsource\n\nextract_features\n\n extract_features (feature_name:str, use_cached:bool=True)\n\nExtract features from a model and save to disk.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfeature_name\nstr\n\nsame as model name. In case different encoders are available, it is in model_encoder format\n\n\nuse_cached\nbool\nTrue\nIf True, rerun extraction even if the features are saved. Defaults to True.\n\n\nReturns\nndarray\n\nfeature array\n\n\n\n\n\nCode\ndef folder_to_word(remove_digit_underscore: bool, # Remove digit and underscore from object names if true. Note that you need the digits to get the task embeddings, but not for the others. If True, the underscore gets replaced with a space.\n                   ) -&gt; list: # List of object names\n    \"\"\"\n    Read file name directories and format them into words by parsing directories\n    and, on demand, removing any numbers and underscores.\n    \"\"\"\n    project_root = get_project_root()\n    with open(join(project_root, \"data\", \"features\", \"file_names.txt\"), \"r\") as f:\n        file_names = f.read()[:-1]  # there is an empty line in the end\n\n    file_names = file_names.split(\"\\n\")\n    file_names = [os.path.dirname(x) for x in file_names]\n    file_names = [os.path.basename(x) for x in file_names]\n\n    if remove_digit_underscore:\n        file_names = [\"\".join([i for i in x if not i.isdigit()]) for x in file_names]\n        file_names = [x.replace(\"_\", \" \") for x in file_names]\n    return file_names\n\n\n\nsource\n\n\nfolder_to_word\n\n folder_to_word (remove_digit_underscore:bool)\n\nRead file name directories and format them into words by parsing directories and, on demand, removing any numbers and underscores.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nremove_digit_underscore\nbool\nRemove digit and underscore from object names if true. Note that you need the digits to get the task embeddings, but not for the others. If True, the underscore gets replaced with a space.\n\n\nReturns\nlist\nList of object names\n\n\n\n\n\nCode\ndef get_visual_embedding(project_root: str, # Root directory of the project\n                         feature_name: str # Name of the feature to extract. Must be in `model_config.json`\n                         ) -&gt; np.ndarray: # total images by features array\n    \"\"\"\n    Extract visual embedding using `thingsvision`\n    \"\"\"\n\n    harmonization_variants = {\n    \"ViT_B16\": load_ViT_B16,\n    \"ResNet50\": load_ResNet50,\n    \"VGG16\": load_VGG16,\n    \"EfficientNetB0\": load_EfficientNetB0,\n    \"tiny_ConvNeXT\": load_tiny_ConvNeXT,\n    \"tiny_MaxViT\": load_tiny_MaxViT,\n    \"LeViT_small\": load_LeViT_small,\n    }\n\n    with open(join(project_root, \"data\", \"model_configs.json\")) as f:\n        file = json.load(f)\n    model_config = file[feature_name]\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    model_parameters = None\n    save_name = feature_name\n    if feature_name.startswith(\"Harmonization\"):\n        extractor = get_extractor_from_model(\n            model=harmonization_variants[feature_name.split(\"Harmonization_\")[-1]](), \n            device=device,\n            backend=\"tf\",\n            )\n    else:\n\n        if feature_name.startswith(\"clip\"):\n            model_parameters = {\"variant\": feature_name.split(\"clip_\")[1]}\n            save_name = feature_name\n            feature_name = \"clip\"\n\n        save_name = save_name.replace(\"/\", \"_\")\n        extractor = get_extractor(\n            model_name=feature_name,\n            source=model_config[\"source\"],\n            device=device,\n            pretrained=True,\n            model_parameters=model_parameters,\n        )\n\n    stimuli_path = join(project_root, \"stimuli\")\n    batch_size = 1\n\n    dataset = ImageDataset(\n        root=stimuli_path,\n        out_path=join(project_root, \"data\", \"features\"),\n        backend=extractor.get_backend(),\n        transforms=extractor.get_transformations(),\n    )\n    batches = DataLoader(\n        dataset=dataset, batch_size=batch_size, backend=extractor.get_backend()\n    )\n\n    flatten_acts = False if feature_name.startswith(\"vit_\") else True\n\n    extractor.extract_features(\n        batches=batches,\n        module_name=model_config[\"module_name\"],\n        flatten_acts=flatten_acts,\n        output_dir=join(project_root, \"data\", \"temp\", save_name),\n        step_size=1,\n    )\n\n    \n    features = cleanup_temp(project_root,save_name)\n\n\n    return features\n\n\n\nsource\n\n\nget_visual_embedding\n\n get_visual_embedding (project_root:str, feature_name:str)\n\nExtract visual embedding using thingsvision\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nproject_root\nstr\nRoot directory of the project\n\n\nfeature_name\nstr\nName of the feature to extract. Must be in model_config.json\n\n\nReturns\nndarray\ntotal images by features array\n\n\n\n\n\nCode\ndef cleanup_temp(project_root:str, # Root directory of the project\n                 save_name:str # name of the feature. has to match folder name under temp\n                 ) -&gt; np.ndarray: # total images by features array\n    \"\"\"\n    Read features for single images from the temp folder.\n\n    Combine them into one large array.\n\n    If all the features are available for all images, delete the feature folder\n    under temp, and return the large array.\n    \"\"\"\n\n    TOTAL_IMAGES = 26107\n\n    temp_list = (glob.glob(join(project_root,'data','temp',save_name,'*npy')))\n    temp_list_sorted = sorted(temp_list,key=lambda x:int(''.join(filter(str.isdigit,x))))\n\n    # below we index into 0 for generality\n    # it allows to extract the CLS from pytorch transformers\n    # while having no effect on other embeddings, which are 1D vectors\n    feature_array = np.array([np.load(x)[0,:] for x in temp_list_sorted])\n\n    assert feature_array.shape[0] == TOTAL_IMAGES, \\\n    f\"There are features for only {feature_array.shape[0]} images.\\nIt must be\\\n        {TOTAL_IMAGES} instead.\\n temp won't be deleted and feature array won't be saved.\"\n    \n\n    return feature_array\n\n\n\nsource\n\n\ncleanup_temp\n\n cleanup_temp (project_root:str, save_name:str)\n\nRead features for single images from the temp folder.\nCombine them into one large array.\nIf all the features are available for all images, delete the feature folder under temp, and return the large array.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nproject_root\nstr\nRoot directory of the project\n\n\nsave_name\nstr\nname of the feature. has to match folder name under temp\n\n\nReturns\nndarray\ntotal images by features array\n\n\n\n\n\nCode\ndef get_ada_embedding(text:str, # Sentence to be embedded \n                      model: str=\"text-embedding-ada-002\" # Model to get embeddings from. Defaults to \"text-embedding-ada-002\".\n                      ) -&gt; np.ndarray: # word vector\n    \"\"\"\n    Generate word embeddings from openai ada model.\n    \"\"\"\n    text = text.replace(\"\\n\", \" \")\n    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n\n\n\nsource\n\n\nget_ada_embedding\n\n get_ada_embedding (text:str, model:str='text-embedding-ada-002')\n\nGenerate word embeddings from openai ada model.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntext\nstr\n\nSentence to be embedded\n\n\nmodel\nstr\ntext-embedding-ada-002\nModel to get embeddings from. Defaults to “text-embedding-ada-002”.\n\n\nReturns\nndarray\n\nword vector"
  },
  {
    "objectID": "learners.html",
    "href": "learners.html",
    "title": "Learner Classes",
    "section": "",
    "text": "Learning models used in both tasks.\n\n\n\nimport numpy as np\nfrom sklearn.linear_model import BayesianRidge, LogisticRegression\nfrom sklearn.base import clone\n\n\n\nCode\nclass CategoryLearner:\n\n    def __init__(self, estimator=LogisticRegression(max_iter=4000) # Linear model to be used for the task. Defaults to `sklearn.linear_model.LogisticRegression`.\n                 ):\n        \"\"\"\n        A class of agent that is used to model the category-learning learning task\n        using a linear model of choosing.\n        \"\"\"\n        self.estimator = estimator\n        # below are place holders\n        self.X = np.zeros(1)\n        self.y = np.zeros(1)\n        self.values = np.zeros(1)\n        self.weights = np.zeros(1)\n        self.mean = 0\n        self.std = 1\n\n    def _predict(self, trial: int):\n        \"\"\"\n        Make predictions for the observation for the given trial\n\n        Args:\n            trial (int): trial number\n        \"\"\"\n\n        # scale test\n        X_test = self.X[trial] - self.mean\n        X_test /= self.std\n        X_test = X_test.reshape(1, -1)\n\n\n        self.values[trial, :] =  self.estimator.predict_proba(X_test)\n\n    def _learn(self, trial: int):\n        \"\"\"\n\n        Fit the model on observations up until the given trial.\n        If that does not include observations belonging to both classes,\n        use the pseudo-observations to make predictions\n\n        Args:\n            trial (int): trial number\n        \"\"\"\n\n        if 0 in self.y[: trial + 1] and 1 in self.y[: trial + 1]:\n            self.estimator = clone(self.estimator)\n            train_X = self.X[: trial + 1]\n\n            # update scaling parameters\n            self.mean = train_X.mean(axis=0)\n            self.std = train_X.std(axis=0)\n            self.std = np.where(self.std==0,1,self.std)\n\n            train_X -= self.mean\n            train_X /= self.std\n\n            self.estimator.fit(train_X, self.y[: trial + 1])\n\n    def fit(self, X: np.ndarray, # Observations\n            y: np.ndarray): # Category\n        \"\"\"\n        Fit the model to the task in a sequential manner like participants did the task.\n        \n        Also save the evolving weights into an array.\n\n        See the structure needed for X and y in the `helpers` module.\n        \"\"\"\n\n        self.X = X\n        self.y = y\n        self.values = np.zeros((self.X.shape[0], 2))\n        self.weights = np.zeros([self.X.shape[0], self.X.shape[1]])\n\n        # give pseudo-observations so the model can make predictions\n        self.estimator.fit(np.zeros((2, self.X.shape[1])), np.array([0, 1]))\n\n        for trial in range(self.X.shape[0]):\n            self._predict(trial)\n            self._learn(trial)\n            self.weights[trial, :] = self.estimator.coef_\n\n\n\nsource\n\nCategoryLearner\n\n CategoryLearner (estimator=LogisticRegression(max_iter=4000))\n\nA class of agent that is used to model the category-learning learning task using a linear model of choosing.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimator\nLogisticRegression\nLogisticRegression(max_iter=4000)\nLinear model to be used for the task. Defaults to sklearn.linear_model.LogisticRegression.\n\n\n\n\nsource\n\n\nCategoryLearner.fit\n\n CategoryLearner.fit (X:numpy.ndarray, y:numpy.ndarray)\n\nFit the model to the task in a sequential manner like participants did the task.\nAlso save the evolving weights into an array.\nSee the structure needed for X and y in the helpers module.\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\nObservations\n\n\ny\nndarray\nCategory\n\n\n\n\n\nCode\nclass RewardLearner:\n\n    def __init__(self, estimator=BayesianRidge() #  Linear model to be used for the task. Defaults to `sklearn.linear_model.BayesianRidge`.\n                 ):\n        \"\"\"\n        A class of agent that is used to model the reward-guided learning task\n        using a linear model of choosing.\n\n        \"\"\"\n        self.estimator = estimator\n        # below are place holders\n        self.X = np.zeros(1)\n        self.y = np.zeros(1)\n        self.values = np.zeros(1)\n        self.weights = np.zeros(1)\n\n    def fit(self, X: np.ndarray, # Observations\n            y: np.ndarray # Reward\n            ):\n        \"\"\"\n        Fit the model to the task in a sequential manner like participants did the task.\n        \n        Also save the evolving weights into an array\n        \n        See the structure needed for X and y in the `helpers` module.\n        \"\"\"\n\n        self.X, self.y = X, y\n        self.values = np.zeros([self.X.shape[0], 2])\n        self.weights = np.zeros([self.X.shape[0], self.X.shape[2]])\n\n        # initialise scaling values\n        mean = np.zeros(self.X.shape[2])\n        std = np.ones(self.X.shape[2])\n\n        for trial in range(self.X.shape[0]):\n            test_X = self._get_test_data(trial)\n\n            # scale test data \n            test_X -= mean\n            test_X /= std\n            self._predict(test_X, trial)\n\n            training_X, training_y = self._get_training_data(trial)\n\n            # get scaling parameters for training data\n            mean = training_X.mean(axis=0)\n            std = training_X.std(axis=0)\n            std = np.where(std==0,1,std)\n\n            training_X -= mean\n            training_X /= std\n\n            self._learn(training_X, training_y)\n            self.weights[trial, :] = self.estimator.coef_\n\n    def _predict(self, test_X: np.ndarray, trial: int):\n        \"\"\"\n        Make predictions for the giben observations and save them.\n        Leave 0 predictions for the first trial for both options.\n\n        Args:\n            test_X (np.ndarray): novel observations -&gt; option (right==1) x feature\n            trial (int): trial number\n        \"\"\"\n        if trial:\n            self.values[trial, 0] = self.estimator.predict(test_X[0].reshape(1, -1))\n            self.values[trial, 1] = self.estimator.predict(test_X[1].reshape(1, -1))\n\n    def _learn(self, training_X: np.ndarray, training_y: np.ndarray):\n        \"\"\"\n        Fit model to given data. Clone the used estimator by detaching the data.\n\n        Args:\n            training_X (np.ndarray): observations -&gt; trial (interleaved both options) x feature\n            training_y (np.ndarray): rewards -&gt; trial (interleaved both options)\n        \"\"\"\n        self.estimator = clone(self.estimator)\n        self.estimator.fit(training_X, training_y.ravel())\n\n    def _get_test_data(self, trial: int):\n        \"\"\"\n        Collapse 3D observations into 2D by having the two options in an interleaved manner\n        in axis 0. Axis 1 is features.\n\n        Args:\n            trial (int): trial number\n\n        \"\"\"\n\n        test_X = np.stack([self.X[trial, 0, :], self.X[trial, 1, :]], axis=0)\n\n        return test_X\n\n    def _get_training_data(self, trial: int):\n        \"\"\"\n        Collapse 3D observations into 2D by merging trial (axis 0) and options (axis 2)\n        axes into axis 0, where we have options in an interleaved manner.\n\n        Collapse 2D rewards into 1D where trials and options are interleaved in the same\n        manner as axis 0.\n\n        Args:\n            trial (int): trial number\n        \"\"\"\n        training_X = np.concatenate(\n            [self.X[: trial + 1, 0, :], self.X[: trial + 1, 1, :]], axis=0\n        )\n        training_y = np.concatenate(\n            [self.y[: trial + 1, 0], self.y[: trial + 1, 1]], axis=0\n        )[:, np.newaxis]\n\n        return training_X, training_y\n\n\n\nsource\n\n\nRewardLearner\n\n RewardLearner (estimator=BayesianRidge())\n\nA class of agent that is used to model the reward-guided learning task using a linear model of choosing.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimator\nBayesianRidge\nBayesianRidge()\nLinear model to be used for the task. Defaults to sklearn.linear_model.BayesianRidge.\n\n\n\n\nsource\n\n\nRewardLearner.fit\n\n RewardLearner.fit (X:numpy.ndarray, y:numpy.ndarray)\n\nFit the model to the task in a sequential manner like participants did the task.\nAlso save the evolving weights into an array\nSee the structure needed for X and y in the helpers module.\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\nObservations\n\n\ny\nndarray\nReward"
  },
  {
    "objectID": "helpers.html",
    "href": "helpers.html",
    "title": "Helper Functions",
    "section": "",
    "text": "All the helper functions used in the project\n\n\n\nimport json\nimport argparse\nimport string\nimport glob\nimport os\nfrom os.path import join\nfrom typing import Tuple\n\nimport numpy as np\nimport pandas as pd\n\n\n\nCode\ndef get_project_root(\n        ) -&gt; str: # project root\n    \"\"\"\n    Return project root based on device.\n    \n    Reads the NATURALCOGSCI_ROOT environment variable\n    \"\"\"\n\n    return os.getenv('NATURALCOGSCI_ROOT')\n\n\n\nsource\n\nget_project_root\n\n get_project_root ()\n\nReturn project root based on device.\nReads the NATURALCOGSCI_ROOT environment variable\n\n\nCode\ndef prepare_training(\n    task: str, # 'reward_learning' or 'category_learning'\n    features: str, # which embedding to use. must match the saved .txt files\n    cond_file: int # number of the condtion file to prepare arrays for\n) -&gt; Tuple[np.ndarray, np.ndarray]: # X,y arrays\n    \"\"\"\n    Prepares the observations and the target values to train models on,\n    for the given condition file and the given task. The returned arrays\n    have the shapes shown in the tables below.\n\n    \"\"\"\n\n    tasks = [\"reward_learning\", \"category_learning\"]\n    assert task in tasks, f\"{task} must be one of {tasks}\"\n\n    project_root = get_project_root()\n\n    df = pd.read_csv(join(project_root, \"data\", \"human_behavioural\", task, \"all.csv\"))\n    df = df[df.cond_file == cond_file].reset_index(drop=True)\n\n    with open(join(project_root, \"data\", \"features\", \"file_names.txt\"), \"r\") as f:\n        file_names = f.read()\n\n    file_names = file_names.split(\"\\n\")[:-1]\n    file_names = [file_name.split(\"NaturalCogSci/\")[1] for file_name in file_names]\n    embedding = np.loadtxt(join(project_root, \"data\", \"features\", f\"{features}.txt\"))\n    if task == \"reward_learning\":\n        TRIALS = 60\n        OPTIONS = 2\n\n        left_stimuli = df.left_image.to_list()\n        right_stimuli = df.right_image.to_list()\n\n        left_stimuli = [\n            file_names.index(left_stimulus) for left_stimulus in left_stimuli\n        ]\n        right_stimuli = [\n            file_names.index(right_stimulus) for right_stimulus in right_stimuli\n        ]\n\n        X = np.zeros((TRIALS, OPTIONS, embedding.shape[1]))\n        X[:, 0, :] = embedding[left_stimuli, :]\n        X[:, 1, :] = embedding[right_stimuli, :]\n\n        y = np.zeros((TRIALS, OPTIONS))\n        y[:, 0] = df.left_reward.to_list()\n        y[:, 1] = df.right_reward.to_list()\n\n    elif task == \"category_learning\":\n        TRIALS = 120\n\n        stimuli = df.image.to_list()[:120]\n\n        stimuli = [file_names.index(stimulus) for stimulus in stimuli]\n\n        X = np.zeros((TRIALS, embedding.shape[1]))\n        X[:] = embedding[stimuli, :]\n        y = df.true_category_binary.to_numpy()[:120]\n\n    return X, y\n\n\n\nsource\n\n\nprepare_training\n\n prepare_training (task:str, features:str, cond_file:int)\n\nPrepares the observations and the target values to train models on, for the given condition file and the given task. The returned arrays have the shapes shown in the tables below.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ntask\nstr\n‘reward_learning’ or ‘category_learning’\n\n\nfeatures\nstr\nwhich embedding to use. must match the saved .txt files\n\n\ncond_file\nint\nnumber of the condtion file to prepare arrays for\n\n\nReturns\nTuple\nX,y arrays\n\n\n\nCategory Learning\n\n\n\nArray\nDim 1\nDim 2\n\n\n\n\nX\ntrial\nfeatures\n\n\ny\ntrial\n\n\n\n\nReward Learning\n\n\n\nArray\nDim 1\nDim 2\nDim 3\n\n\n\n\nX\ntrial\noptions (left==0)\nfeatures\n\n\ny\ntrial\noptions (left==0)\n\n\n\n\n\n\nCode\ndef str2bool(v : str|bool, # input from the command line\n             ) -&gt; bool: # Python Boolean\n    \"\"\"\n    Used to parse boolean command line arguments for Python.\n    \"\"\"\n    if v == \"true\":\n        return True\n    elif v == \"false\":\n        return False\n    else:\n        raise argparse.ArgumentTypeError(\"Boolean value expected.\")\n\n\n\nsource\n\n\nstr2bool\n\n str2bool (v:str|bool)\n\nUsed to parse boolean command line arguments for Python.\n\n\n\n\nType\nDetails\n\n\n\n\nv\nstr | bool\ninput from the command line\n\n\nReturns\nbool\nPython Boolean\n\n\n\n\n\nCode\ndef id_generator(\n    size: int = 10, # length of ID\n    chars: str = string.ascii_uppercase + string.digits, # characters to use\n) -&gt; str: # unique ID\n    \"\"\"\n    Used to generate IDs for participants. This is to hide their Prolific IDs.\n    \"\"\"\n    return \"\".join(np.random.choice(list(chars), size=size))\n\n\n\nsource\n\n\nid_generator\n\n id_generator (size:int=10,\n               chars:str='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')\n\nUsed to generate IDs for participants. This is to hide their Prolific IDs.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsize\nint\n10\nlength of ID\n\n\nchars\nstr\nABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\ncharacters to use\n\n\nReturns\nstr\n\nunique ID\n\n\n\n\n\nCode\ndef parse_reward_data() -&gt; None:\n    \"\"\"\n    Read and parse json data and condition files of reward learning into pandas dataframes.\n    \n    Make 2 dataframes:\n\n    1. all_df: includes all participants\n    2. keep_df: includes only those with above 50% accuracy\n    \"\"\"\n\n    project_root = get_project_root()\n    BASE_PAY = 2.0\n    TRIAL_NO = 60\n\n    beh_files = glob.glob(\n        join(project_root, \"experiments\", \"reward_learning\", \"data\", \"*json\")\n    )\n    df_list = []\n\n    for beh_file_path in beh_files:\n        with open(beh_file_path) as f:\n            beh_file = json.load(f)\n\n        beh_file_no = os.path.splitext(os.path.basename(beh_file_path))[0]\n\n        with open(\n            join(\n                project_root,\n                \"experiments\",\n                \"reward_learning\",\n                \"condition_files\",\n                f\"{beh_file_no}.json\",\n            )\n        ) as f:\n            cond_file = json.load(f)\n\n        par_df = pd.DataFrame(\n            {\n                \"left_image\": list(cond_file[\"arm_0_image\"].values()),\n                \"right_image\": list(cond_file[\"arm_1_image\"].values()),\n                \"dimension\": list(cond_file[\"reward_dimension\"].values()),\n                \"left_reward\": list(cond_file[\"arm_0_reward\"].values()),\n                \"right_reward\": list(cond_file[\"arm_1_reward\"].values()),\n                \"max_reward\": list(cond_file[\"max_reward\"].values()),\n                \"min_reward\": list(cond_file[\"min_reward\"].values()),\n                \"choice\": beh_file[\"choices\"],\n                \"reward_received\": beh_file[\"points\"],\n                \"cond_file\": beh_file_no,\n                \"trial\": range(TRIAL_NO)\n            }\n        )\n\n        par_df[\"bonus_payment\"] = float(beh_file[\"money\"]) - BASE_PAY\n        par_df[\"include\"] = np.where(beh_file[\"include\"] == \"yes\", 1, 0)\n        par_df[\"participant\"] = id_generator()\n        par_df[\"regret\"] = par_df[\"max_reward\"] - par_df[\"reward_received\"]\n        par_df[\"chance_regret\"] = (par_df[\"max_reward\"] - par_df[\"min_reward\"]) / 2\n        par_df[\"correct\"] = np.where(par_df.regret == 0, 1, 0)\n        df_list.append(par_df)\n\n    all_df = pd.concat(df_list)\n    filter_chance(all_df, \"reward_learning\")\n    return None\n\n\n\nsource\n\n\nparse_reward_data\n\n parse_reward_data ()\n\nRead and parse json data and condition files of reward learning into pandas dataframes.\nMake 2 dataframes:\n\nall_df: includes all participants\nkeep_df: includes only those with above 50% accuracy\n\n\n\nCode\ndef parse_category_data() -&gt; None:\n    \"\"\"\n    Read and parse behavioural csv files of category learning into pandas dataframes.\n\n    Make 2 dataframes:\n    1. all_df: includes all participants\n    2. keep_df: includes only those with above 50% accuracy\n    \"\"\"\n    BASE_PAY = 1.5\n    TRIAL_NO = 120\n\n    project_root = get_project_root()\n\n    beh_files = glob.glob(\n        join(project_root, \"experiments\", \"category_learning\", \"data\", \"task_*.csv\")\n    )\n    df_list = []\n\n    for beh_file in beh_files:\n        df = pd.read_csv(beh_file)\n        trial_df = df[df.trial_type == \"image-keyboard-response\"].reset_index(drop=True)\n\n        par_df = pd.DataFrame(\n            {\n                \"image\": trial_df.stimulus.to_list(),\n                \"choice\": np.where(trial_df.response == \"j\", 1, 0),\n                \"true_category_name\": trial_df.trueCategory,\n                \"true_category_binary\": np.where(\n                    trial_df.trueCategory == \"Julty\", 1, 0\n                ),\n                \"correct\": trial_df.correct,\n                \"cond_file\": trial_df.cond_file_no,\n                \"participant\": id_generator(),\n                \"include\": np.where(\n                    json.loads((df.tail(1)[\"response\"]).values[0])[\"include\"] == \"Yes\",\n                    1,\n                    0,\n                ),\n                \"bonus_payment\": np.round(float(df.tail(1).current_pay) - BASE_PAY, 2),\n                \"dimension\": (trial_df.cond_file_no - 1) % 3,\n                \"trial\": range(TRIAL_NO)\n            }\n        )\n\n        df_list.append(par_df)\n\n    all_df = pd.concat(df_list)\n    filter_chance(all_df, \"category_learning\")\n\n    return None\n\n\n\nsource\n\n\nparse_category_data\n\n parse_category_data ()\n\nRead and parse behavioural csv files of category learning into pandas dataframes.\nMake 2 dataframes: 1. all_df: includes all participants 2. keep_df: includes only those with above 50% accuracy\n\n\nCode\ndef filter_chance(df: pd.DataFrame, # dataframe to filter\n                  task: str # 'reward_learning' or 'category_learning'\n                  ) -&gt; None:\n    \"\"\"\n    Take large behavioural df, and make two copies:\n\n    1.Dataframe as is\n    2. Dataframe with $p(correct) &gt; .5$ & those who said their data should be included\n\n    Write these on the disk.\n    \"\"\"\n\n    allowed_tasks = [\"reward_learning\", \"category_learning\"]\n    assert task in allowed_tasks, f\"{task} not in {allowed_tasks}\"\n\n    project_root = get_project_root()\n    df.to_csv(\n        join(project_root, \"data\", \"human_behavioural\", task, \"all.csv\"),\n        index=False,\n    )\n    accuracy_df = df.groupby([\"participant\", \"include\"], as_index=False)[\n        \"correct\"\n    ].mean()\n    keep_participants = accuracy_df[\n        (accuracy_df.correct &gt; 0.5) & (accuracy_df.include == True)\n    ].participant.to_list()\n    keep_df = df[df.participant.isin(keep_participants)].reset_index(drop=True)\n\n    keep_df.to_csv(\n        join(project_root, \"data\", \"human_behavioural\", task, \"above_chance.csv\"),\n        index=False,\n    )\n    return None\n\n\n\nsource\n\n\nfilter_chance\n\n filter_chance (df:pandas.core.frame.DataFrame, task:str)\n\nTake large behavioural df, and make two copies:\n1.Dataframe as is 2. Dataframe with p(correct) &gt; .5 & those who said their data should be included\nWrite these on the disk.\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\ndataframe to filter\n\n\ntask\nstr\n‘reward_learning’ or ‘category_learning’\n\n\nReturns\nNone"
  },
  {
    "objectID": "bin/behavioural_analyses.html",
    "href": "bin/behavioural_analyses.html",
    "title": "Behavioural Analyses",
    "section": "",
    "text": "Below is the code for the mixed-models that predict participant choice using task parameters.\nlibrary(lme4)\nlibrary(tidyverse)\nlibrary(broom.mixed)\n\nproject_root &lt;- Sys.getenv(\"NATURALCOGSCI_ROOT\")\n\n\n# category learning\n\ncategory_df &lt;- read_csv(file.path(\n  project_root, \"data\", \"human_behavioural\", \"category_learning\",\n  \"above_chance.csv\"\n))\n\ncategory_df &lt;- category_df %&gt;% mutate(trial = scale(trial))\ncategory_df &lt;- category_df %&gt;% mutate(dimension = as.factor(dimension))\n\ncategory_glmm &lt;- glmer(\n  correct ~ 1 + trial + (1 + trial + dimension | participant),\n  data = category_df,\n  family = binomial\n)\n\ncategory_glmm_df &lt;- tidy(category_glmm)[1:2, ]\n\n# write tibble as csv\n\nwrite_csv(category_glmm_df, file.path(\n  project_root, \"data\", \"human_behavioural\", \"category_learning\",\n  \"glmm.csv\"\n))\n\n\n\n# reward_learning\n\nreward_df &lt;- read_csv(file.path(\n  project_root, \"data\", \"human_behavioural\", \"reward_learning\",\n  \"above_chance.csv\"\n))\n\nreward_df &lt;- reward_df %&gt;% mutate(trial = scale(trial))\nreward_df &lt;- reward_df %&gt;% mutate(dimension = as.factor(dimension))\nreward_df &lt;- reward_df %&gt;% mutate(rl_diff = scale(right_reward - left_reward))\n\nreward_glmm &lt;- glmer(\n  choice ~ -1 + trial * rl_diff +\n  (-1 + trial + dimension + rl_diff | participant),\n  data = reward_df,\n  family = binomial\n)\n\nreward_glmm_df &lt;- tidy(reward_glmm)[1:3, ]\nwrite_csv(reward_glmm_df, file.path(\n  project_root, \"data\", \"human_behavioural\", \"reward_learning\",\n  \"glmm.csv\"\n))"
  },
  {
    "objectID": "bin/visualisations.html",
    "href": "bin/visualisations.html",
    "title": "Visualisations",
    "section": "",
    "text": "Code\nimport string\nfrom os.path import join\nimport glob\nimport json\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.patheffects as pe\nfrom matplotlib.lines import Line2D\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import kendalltau, ttest_1samp\n\n\nimport torch\nfrom thingsvision import get_extractor, get_extractor_from_model\nfrom tqdm import tqdm\n\nfrom harmonization.models import (\n    load_ViT_B16,\n    load_ResNet50,\n    load_VGG16,\n    load_EfficientNetB0,\n    load_tiny_ConvNeXT,\n    load_tiny_MaxViT,\n    load_LeViT_small,\n)\n\n\nfrom NaturalCogSci.helpers import get_project_root"
  },
  {
    "objectID": "bin/visualisations.html#imports",
    "href": "bin/visualisations.html#imports",
    "title": "Visualisations",
    "section": "",
    "text": "Code\nimport string\nfrom os.path import join\nimport glob\nimport json\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.patheffects as pe\nfrom matplotlib.lines import Line2D\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import kendalltau, ttest_1samp\n\n\nimport torch\nfrom thingsvision import get_extractor, get_extractor_from_model\nfrom tqdm import tqdm\n\nfrom harmonization.models import (\n    load_ViT_B16,\n    load_ResNet50,\n    load_VGG16,\n    load_EfficientNetB0,\n    load_tiny_ConvNeXT,\n    load_tiny_MaxViT,\n    load_LeViT_small,\n)\n\n\nfrom NaturalCogSci.helpers import get_project_root"
  },
  {
    "objectID": "bin/visualisations.html#plotting-parameters",
    "href": "bin/visualisations.html#plotting-parameters",
    "title": "Visualisations",
    "section": "Plotting Parameters",
    "text": "Plotting Parameters\n\n\nCode\nmpl.rcParams['axes.spines.right'] = False\nmpl.rcParams['axes.spines.top'] = False\n\nFIGWIDTH = 6.99866\nCATEGORYTRIALS = 120\nREWARDTRIALS = 60\n\nproject_root = get_project_root()\nwith open(join(project_root, \"data\", \"model_plot_params.json\")) as f:\n    plot_params = json.load(f)\nplot_params = {k.replace(\"/\",\"_\"):v for k,v in plot_params.items()}\n\n\ncmap = [\"#7570B3\",\"#D95F02\",\"#A6761D\",\"#1B9E77\",\"#972D15\",\"#E6AB02\",\"#666666\"]\nsns.set_palette(cmap)\nsns.color_palette(cmap)\n\n\n\nSMALL_SIZE = 8\nMEDIUM_SIZE = 10\nBIGGER_SIZE = 12\n\nplt.rc('font', size=SMALL_SIZE)          # controls default text sizes\nplt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\nplt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\nplt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\nplt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\nplt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\nplt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n\n\nlatex_context = {\n    \"pgf.texsystem\": \"pdflatex\",\n    'font.family': 'serif',\n    'text.usetex': True,\n    'pgf.rcfonts': False,\n}\n\n\n# retina figures\nmpl.rcParams['figure.dpi'] = 300\nmpl.rcParams['savefig.dpi'] = 300"
  },
  {
    "objectID": "bin/visualisations.html#main-figures",
    "href": "bin/visualisations.html#main-figures",
    "title": "Visualisations",
    "section": "Main Figures",
    "text": "Main Figures\n\nCategory Learning\n\n\nCode\nfig = plt.figure(layout=\"constrained\",figsize=(FIGWIDTH, FIGWIDTH))\n\nspec = fig.add_gridspec(2, 3)\nax00 = fig.add_subplot(spec[0, 0])\nax00.text(-0.4, 1.1, string.ascii_uppercase[0], transform=ax00.transAxes, weight='bold')\n\n\n\nbehavioural_df = pd.read_csv(join(project_root, \"data\", \"human_behavioural\", \"category_learning\", \"above_chance.csv\"))\nsns.lineplot(data=behavioural_df,x=\"trial\",y=\"correct\",ax=ax00,color=cmap[-2])\nax00.set_xlabel(\"Trial\")\nax00.set_ylabel(\"p(Correct)\")\nax00.set_ylim(.4,.9)\nax00.axhline(.5,ls=\"--\",color=cmap[-1],lw=1)\nax00.set_xticks([0,40,80,120])\n# make x ticks 1 indexed\n\n\nax01 = fig.add_subplot(spec[0, 1])\nax01.text(-0.1, 1.1, string.ascii_uppercase[1], transform=ax01.transAxes, weight='bold')\n\nglmm_df = pd.read_csv(join(project_root, \"data\", \"human_behavioural\", \"category_learning\", \"glmm.csv\"))\nglmm_df = glmm_df.replace(['(Intercept)', 'trial'], [\"Intercept\", \"Trial\"])\nax01.bar(glmm_df['term'],glmm_df['estimate'],color=cmap[-2],edgecolor=cmap[-1],lw=1,width=0.8)\nax01.set_ylabel(r'$\\hat{\\beta}$',rotation=0,labelpad=10)\nax01.set_ylim(ymin=0,ymax=1.5)\nax01.set_yticks([0,.5,1,1.5])\n\n\nfor regressor in glmm_df['term'].values:\n\n    ax01.plot([regressor,regressor],\n    [float(glmm_df[glmm_df['term']==regressor]['estimate'] + glmm_df[glmm_df['term']==regressor]['std.error']),\n    float(glmm_df[glmm_df['term']==regressor]['estimate'] - glmm_df[glmm_df['term']==regressor]['std.error'])],\n    color=cmap[-1],lw=1)\n\n    \n\nax01.annotate('***',xy=('Intercept', 1.35), weight='bold',ha='center')\nax01.annotate('***', xy=('Trial', .4), weight='bold',ha='center')\n\nax02 = fig.add_subplot(spec[0, 2])\nax02.text(-0.1, 1.1, string.ascii_uppercase[2], transform=ax02.transAxes, weight='bold')\n\nbest_models = [\n    join(project_root, \"data\", \"learner_behavioural\", \"category_learning\", \"clip_ViT-L_14_l2_original.csv\"),\n    join(project_root, \"data\", \"learner_behavioural\", \"category_learning\", \"vit_h_14_l2_original.csv\"),\n    join(project_root, \"data\", \"learner_behavioural\", \"category_learning\", \"task_l2_original.csv\"),\n    join(project_root, \"data\", \"learner_behavioural\", \"category_learning\", \"universal_sentence_encoder_l2_original.csv\"),\n    join(project_root, \"data\", \"learner_behavioural\", \"category_learning\", \"dino-rn50_l2_original.csv\"),\n\n\n]\n\nbest_models = [pd.read_csv(x) for x in best_models]\nbest_models = pd.concat(best_models)\nbest_models[\"model_correct\"] = np.where(best_models.true_category_binary == 1, best_models.prob, 1-best_models.prob)\nbest_models[\"model_correct\"] = np.where(best_models.model_correct &gt;= .5, 1, 0)\nbest_models[\"colour\"] = best_models[\"features\"].apply(lambda x: plot_params[x][\"colour\"])\nbest_models[\"features\"] = best_models[\"features\"].apply(lambda x: plot_params[x][\"name\"])\nbest_models = best_models.reset_index(drop=True)\n\n# average correct every 5 trials\nbest_models['model_correct'] = best_models.groupby(best_models.index // 10)['model_correct'].transform('mean')\n# take every 5th trial\nbest_models = best_models.iloc[::10, :]\n\nsns.lineplot(data=best_models,x=\"trial\",y=\"model_correct\",hue=\"colour\",\n             ax=ax02,palette=cmap[:-2],errorbar=None,legend=False,\n             hue_order=[\"task\",\"supervised\",\"self-supervised\",\"self-supervised multimodal\",\"text\"])\n\nax02.set_xlabel(\"Trial\")\nax02.set_ylabel(\"p(Correct)\")\nax02.set_ylim(.4,.9)\nax02.axhline(.5,ls=\"--\",color=cmap[-1],lw=1)\nax02.set_xticks([0,40,80,120])\n\n\nax1 = fig.add_subplot(spec[1, :])\ndfs = glob.glob(join(project_root, \"data\", \"learner_behavioural\", \"category_learning\", \"*_l2_original.csv\"))\ndfs = [pd.read_csv(x) for x in dfs]\nmodel_df = pd.concat(dfs)\nmodel_df[\"nll\"] = - np.where(model_df.choice == 1, np.log(model_df.prob), np.log(1-model_df.prob))\nchance_level = - model_df.participant.nunique() * CATEGORYTRIALS * np.log(0.5)\nmodel_df = model_df.groupby(\"features\").agg({\"nll\":\"sum\"}).reset_index()\nmodel_df = model_df.sort_values(by=\"nll\",ascending=True).reset_index(drop=True)\nmodel_df[\"color\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"colour\"])\nmodel_df[\"features\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"name\"])\ncategory_model_df = model_df\n\nsns.barplot(\n    data=model_df,x=\"features\",y=\"nll\",hue=\"color\",dodge=False,ax=ax1,\n    hue_order=[\"task\",\"supervised\",\"self-supervised\",\"self-supervised multimodal\",\"text\"]\n            )\nax1.legend_.remove()\nax1.axhline(chance_level,ls=\"--\",color=cmap[-1])\n# show x-axis ticks in the bars\nax1.xaxis.set_tick_params(rotation=90)\nax1.set_ylabel(\"Negative Log Likelihood\")\nax1.set_xlabel(\"\")\nax1.set_ylim(5000,8000)\nax1.set_yticks([5000,6000,7000,8000])\nax1.yaxis.set_label_coords(-0.07,.4)\nax1.text(-0.1, 1.35, string.ascii_uppercase[3], transform=ax1.transAxes, weight='bold')\ncustom_legend_lines = [Line2D([0], [0], color=x, lw=2, path_effects=[pe.Stroke(linewidth=4, foreground=cmap[-1]), pe.Normal()]) for x in cmap[:-1]]\nhue_order = ['Task','Supervised','Self-Supervised','Self-Supervised\\nMulti-Modal','Language']\nfig.legend(custom_legend_lines, hue_order, loc='center',bbox_to_anchor=(0.54, .58),ncol=5,frameon=False)\nfig.align_ylabels([ax00,ax01,ax02,ax1])\nplt.show()\n\nwith mpl.rc_context(latex_context):\n    fig.savefig(join(project_root, \"figures\",\"category_learning.pdf\"), bbox_inches='tight')\n\n\n/tmp/ipykernel_9745/3663908693.py:33: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n  [float(glmm_df[glmm_df['term']==regressor]['estimate'] + glmm_df[glmm_df['term']==regressor]['std.error']),\n/tmp/ipykernel_9745/3663908693.py:34: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n  float(glmm_df[glmm_df['term']==regressor]['estimate'] - glmm_df[glmm_df['term']==regressor]['std.error'])],\n\n\n\n\n\n\n\nReward Learning\n\n\nCode\nfig = plt.figure(layout=\"constrained\",figsize=(FIGWIDTH, FIGWIDTH))\nspec = fig.add_gridspec(2, 3)\nax00 = fig.add_subplot(spec[0, 0])\nax00.text(-0.4, 1.2, string.ascii_uppercase[0], transform=ax00.transAxes, weight='bold')\n\n\n\nax00.set_xlabel(\"Trial\")\nax00.set_ylabel(\"p(Correct)\")\nax00.set_ylim(.4,.9)\nax00.axhline(.5,ls=\"--\",color=cmap[-1],lw=1)\nbehavioural_df = pd.read_csv(join(project_root, \"data\", \"human_behavioural\", \"reward_learning\", \"above_chance.csv\"))\nsns.lineplot(data=behavioural_df,x=\"trial\",y=\"correct\",ax=ax00,color=cmap[-2])\nax00.set_xlabel(\"Trial\")\nax00.set_ylabel(\"p(Best)\")\nax00.set_ylim(.4,1)\nax00.axhline(.5,ls=\"--\",color=cmap[-1],lw=1)\n\n\nax01 = fig.add_subplot(spec[0, 1])\nax01.text(-0.1, 1.1, string.ascii_uppercase[1], transform=ax01.transAxes, weight='bold')\n\n\n\nglmm_df = pd.read_csv(join(project_root, \"data\", \"human_behavioural\", \"reward_learning\", \"glmm.csv\"))\nglmm_df = glmm_df.replace(['trial', 'rl_diff',\"trial:rl_diff\"], [\"Trial\", \"Reward\\nDiff\",\"Reward\\nDiff x Trial\"])\nglmm_df = glmm_df.reindex([1,0,2])\nax01.bar(glmm_df['term'],glmm_df['estimate'],color=cmap[-2],edgecolor=cmap[-1],lw=1)\nax01.set_ylabel(r'$\\hat{\\beta}$',rotation=0,labelpad=10)\nax01.set_ylim(ymin=0,ymax=1.1)\nax01.annotate('***',xy=('Reward\\nDiff', 1.), weight='bold',ha='center')\nax01.annotate('***', xy=('Reward\\nDiff x Trial', .6), weight='bold',ha='center')\n\n\nfor regressor in glmm_df['term'].values:\n\n    ax01.plot([regressor,regressor],\n    [float(glmm_df[glmm_df['term']==regressor]['estimate'] + glmm_df[glmm_df['term']==regressor]['std.error']),\n    float(glmm_df[glmm_df['term']==regressor]['estimate'] - glmm_df[glmm_df['term']==regressor]['std.error'])],\n    color=cmap[-1],lw=1)\n\nax02 = fig.add_subplot(spec[0, 2])\nax02.text(-0.1, 1.1, string.ascii_uppercase[2], transform=ax02.transAxes, weight='bold')\n\nbest_models = [\n    join(project_root, \"data\", \"learner_behavioural\", \"reward_learning\", \"clip_ViT-L_14_l2_original.csv\"),\n    join(project_root, \"data\", \"learner_behavioural\", \"reward_learning\", \"vit_h_14_l2_original.csv\"),\n    join(project_root, \"data\", \"learner_behavioural\", \"reward_learning\", \"task_l2_original.csv\"),\n    join(project_root, \"data\", \"learner_behavioural\", \"reward_learning\", \"roberta_l2_original.csv\"),\n    join(project_root, \"data\", \"learner_behavioural\", \"reward_learning\", \"resnet34_l2_original.csv\"),\n    join(project_root, \"data\", \"learner_behavioural\", \"reward_learning\", \"dino-rn50_l2_original.csv\"),\n\n\n]\n\nbest_models = [pd.read_csv(x) for x in best_models]\nbest_models = pd.concat(best_models)\nbest_models[\"true_category_binary\"] = np.where(best_models.right_reward &gt;= best_models.left_reward, 1, 0)\nbest_models[\"model_correct\"] = np.where(best_models.true_category_binary == 1, best_models.prob, 1-best_models.prob)\nbest_models[\"model_correct\"] = np.where(best_models.model_correct &gt;= .5, 1, 0)\nbest_models[\"colour\"] = best_models[\"features\"].apply(lambda x: plot_params[x][\"colour\"])\nbest_models[\"features\"] = best_models[\"features\"].apply(lambda x: plot_params[x][\"name\"])\nbest_models = best_models.reset_index(drop=True)\n# average correct every 5 trials after the first trial\n\n\nbest_models['model_correct'] = best_models.groupby(best_models.index // 5)['model_correct'].transform('mean')\n# take every 5th trial\nbest_models = best_models.iloc[::5, :]\n\nsns.lineplot(data=best_models,x=\"trial\",y=\"model_correct\",hue=\"colour\",\n             ax=ax02,palette=cmap[:-2],errorbar=None,legend=False,\n             hue_order=[\"task\",\"supervised\",\"self-supervised\",\"self-supervised multimodal\",\"text\"])\n\nax02.set_xlabel(\"Trial\")\nax02.set_ylabel(\"p(Best)\")\nax02.set_ylim(.4,1)\nax02.axhline(.5,ls=\"--\",color=cmap[-1],lw=1)\nax02.set_xticks([0,20,40,60])\n\nax1 = fig.add_subplot(spec[1, :])\n\ndfs = glob.glob(join(project_root, \"data\", \"learner_behavioural\", \"reward_learning\", \"*_l2_original.csv\"))\ndfs = [pd.read_csv(x) for x in dfs]\nmodel_df = pd.concat(dfs)\nmodel_df[\"prob\"] = np.where(model_df.prob ==1,.99999,model_df.prob)\nmodel_df[\"nll\"] = - np.where(model_df.choice == 1, np.log(model_df.prob), np.log(1-model_df.prob))\nchance_level = - model_df.participant.nunique() * REWARDTRIALS * np.log(0.5)\nmodel_df = model_df.groupby(\"features\").agg({\"nll\":\"sum\"}).reset_index()\nmodel_df = model_df.sort_values(by=\"nll\",ascending=True).reset_index(drop=True)\nmodel_df[\"color\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"colour\"])\nmodel_df[\"features\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"name\"])\nreward_model_df = model_df\n\nsns.barplot(\n    data=model_df,x=\"features\",y=\"nll\",hue=\"color\",dodge=False,ax=ax1,\n    hue_order=[\"task\",\"supervised\",\"self-supervised\",\"self-supervised multimodal\",\"text\"]\n            )\nax1.legend_.remove()\nax1.axhline(chance_level,ls=\"--\",color=cmap[-1])\n# show x-axis ticks in the bars\nax1.xaxis.set_tick_params(rotation=90)\nax1.set_ylabel(\"Negative Log Likelihood\")\nax1.set_xlabel(\"\")\nax1.set_ylim(2500,3500)\nax1.set_yticks([2500,3000,3500])\nax1.yaxis.set_label_coords(-0.07,.4)\nax1.text(-0.1, 1.35, string.ascii_uppercase[3], transform=ax1.transAxes, weight='bold')\ncustom_legend_lines = [Line2D([0], [0], color=x, lw=2, path_effects=[pe.Stroke(linewidth=4, foreground=cmap[-1]), pe.Normal()]) for x in cmap[:-1]]\nhue_order = ['Task','Supervised','Self-Supervised','Self-Supervised\\nMulti-Modal','Language']\nfig.legend(custom_legend_lines, hue_order, loc='center',bbox_to_anchor=(0.54, .58),ncol=5,frameon=False)\nfig.align_ylabels([ax00,ax01,ax02,ax1])\nplt.show()\nwith mpl.rc_context(latex_context):\n    fig.savefig(join(project_root, \"figures\",\"reward_learning.pdf\"), bbox_inches='tight')\n\n\n/tmp/ipykernel_9745/385213310.py:38: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n  [float(glmm_df[glmm_df['term']==regressor]['estimate'] + glmm_df[glmm_df['term']==regressor]['std.error']),\n/tmp/ipykernel_9745/385213310.py:39: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n  float(glmm_df[glmm_df['term']==regressor]['estimate'] - glmm_df[glmm_df['term']==regressor]['std.error'])],\n\n\n\n\n\n\n\nRSA\n\n\nCode\nfig = plt.figure(layout=\"constrained\",figsize=(FIGWIDTH, FIGWIDTH))\nspec = fig.add_gridspec(2,1)\nax00 = fig.add_subplot(spec[0, :])\n\ntask_cka_df = pd.read_csv(join(project_root,\"data\",\"cka\",\"baseline.csv\"))\ntask_cka_df = task_cka_df[task_cka_df.feature != \"cornet-rt\"].reset_index(drop=True)\ntask_cka_df = task_cka_df[task_cka_df.feature != \"task\"].reset_index(drop=True)\ntask_cka_df[\"colour\"] = task_cka_df[\"feature\"].apply(lambda x: plot_params[x][\"colour\"])\n\ntask_cka_df[\"features\"] = task_cka_df[\"feature\"].apply(lambda x: plot_params[x][\"name\"])\n# sort\ntask_cka_df =task_cka_df.sort_values(by=\"cka\",ascending=False).reset_index(drop=True)\n\n\n\nsns.barplot(data=task_cka_df,x=\"features\",y=\"cka\",hue=\"colour\",ax=ax00,dodge=False,\n    hue_order=[\"task\",\"supervised\",\"self-supervised\",\"self-supervised multimodal\",\"text\"])\n\nax00.legend_.remove()\nax00.set_ylabel(\"Similarity (CKA)\\nwith Task Embedding\")     \nax00.xaxis.set_tick_params(rotation=90)\nax00.set_xlabel(\"\")\nax00.text(-0.1, 1.35, string.ascii_uppercase[0], transform=ax00.transAxes, weight='bold')\ncustom_legend_lines = [Line2D([0], [0], color=x, lw=2, path_effects=[pe.Stroke(linewidth=4, foreground=cmap[-1]), pe.Normal()]) for x in cmap[1:-1]]\nhue_order = ['Supervised','Self-Supervised','Self-Supervised\\nMulti-Modal','Language']\nfig.legend(custom_legend_lines, hue_order, loc='center',bbox_to_anchor=(0.54, 1),ncol=5,frameon=False)\n\nax10 = fig.add_subplot(spec[1,:])\nclip_cka_dfs = glob.glob(join(project_root,\"data\",\"cka\",\"*clip*.csv\"))\n\ndiff_dfs = []\n\ntask_cka_df = task_cka_df[task_cka_df.feature != \"cornet-rt\"].reset_index(drop=True)\ntask_cka_df = task_cka_df[task_cka_df.feature != \"task\"].reset_index(drop=True)\ntask_cka_df = task_cka_df[~task_cka_df.feature.str.startswith(\"clip\")].reset_index(drop=True)\nfor i,df_path in enumerate(clip_cka_dfs):\n    df = pd.read_csv(df_path)\n    df = df[df.feature != \"cornet-rt\"].reset_index(drop=True)\n    df = df[df.feature != \"task\"].reset_index(drop=True)\n    df = df[~df.feature.str.startswith(\"clip\")].reset_index(drop=True)\n    df[\"colour\"] = df[\"feature\"].apply(lambda x: plot_params[x][\"colour\"])\n    df[\"features\"] = df[\"feature\"].apply(lambda x: plot_params[x][\"name\"])\n\n    diff_df = pd.merge(task_cka_df,df,on=[\"feature\",\"colour\"],how=\"outer\")\n    diff_df[\"diff\"] = diff_df[\"cka_x\"] - diff_df[\"cka_y\"]\n    diff_df = diff_df.sort_values(by=\"diff\",ascending=False).reset_index(drop=True)\n    diff_dfs.append(diff_df)\n\ndiff_df = pd.concat(diff_dfs)\nnew_sort = diff_df.groupby(\"feature\")['diff'].mean().sort_values(ascending=False)\n\nsorterIndex = dict(zip(new_sort, range(len(new_sort))))\n\ndiff_df['feature_rank'] = diff_df['features_x'].map(sorterIndex)\ndiff_df[\"features\"] = diff_df[\"feature\"].apply(lambda x: plot_params[x][\"name\"])\n\nsns.barplot(data=diff_df,x=\"features\",y=\"diff\",hue=\"colour\",ax=ax10,dodge=False,\n    hue_order=[\"task\",\"supervised\",\"self-supervised\",\"self-supervised multimodal\",\"text\"])\n\nsns.stripplot(\n    data=diff_df,\n    x='features',\n    y='diff',\n    dodge=True,\n    color=cmap[-1],\n    alpha=.8,\n    s=3,\n    hue_order=[\"task\",\"supervised\",\"self-supervised\",\"self-supervised multimodal\",\"text\"],\n    ax=ax10)\n\nax10.legend_.remove()\nax10.set_ylabel(\"CKA${_{Task}}$ $-$ CKA${_{CLIP}}$\")     \nax10.xaxis.set_tick_params(rotation=90)\nax10.set_xlabel(\"\")\nax10.text(-0.1, 1.35, string.ascii_uppercase[1], transform=ax10.transAxes, weight='bold')\n\n\n\nplt.show()\nwith mpl.rc_context(latex_context):\n    fig.savefig(join(project_root, \"figures\",\"representations.pdf\"), bbox_inches='tight')"
  },
  {
    "objectID": "bin/visualisations.html#supplementary-figures",
    "href": "bin/visualisations.html#supplementary-figures",
    "title": "Visualisations",
    "section": "Supplementary Figures",
    "text": "Supplementary Figures\n\np Values For Trials\n\n\nCode\nSINGLECOLWIDTH = 3.4252\nfig, ax = plt.subplots(1,2,figsize=(2*SINGLECOLWIDTH, SINGLECOLWIDTH),sharey=True)\nbehavioural_df = pd.read_csv(join(project_root, \"data\", \"human_behavioural\", \"category_learning\", \"above_chance.csv\"))\n\n# loop through each trial in the behavioural df, and do a t-test against .5\n# record p-values\np_values = []\nfor trial in behavioural_df.trial.unique():\n    p_values.append(ttest_1samp(behavioural_df[behavioural_df.trial == trial].correct, .5)[1])\n\ncategory_p_df = pd.DataFrame({\"trial\":np.array(behavioural_df.trial.unique())+1,\"p\":p_values})\ncategory_p_df[\"sig\"] = np.where(category_p_df.p &lt; .05, 1, 0)\n\nsns.scatterplot(data=category_p_df,x=\"trial\",y=\"p\",hue='sig',ax=ax[0],color=cmap[-2])\n# log scale for y axis\nax[0].set_yscale('log')\nax[0].set_xlabel(\"Trial\")\nax[0].set_ylabel(\"p-value\")\n# dashed grey horizontal line at .05\nax[0].axhline(.05,ls=\"--\",color=cmap[-1],lw=1)\n# remove legend\nax[0].legend_.remove()\n\n# do the same for reward learning\nbehavioural_df = pd.read_csv(join(project_root, \"data\", \"human_behavioural\", \"reward_learning\", \"above_chance.csv\"))\np_values = []\nfor trial in behavioural_df.trial.unique():\n    p_values.append(ttest_1samp(behavioural_df[behavioural_df.trial == trial].correct, .5)[1])\n\nreward_p_df = pd.DataFrame({\"trial\":np.array(behavioural_df.trial.unique())+1,\"p\":p_values})\nreward_p_df[\"sig\"] = np.where(reward_p_df.p &lt; .05, 1, 0)\n\nsns.scatterplot(data=reward_p_df,x=\"trial\",y=\"p\",hue='sig',ax=ax[1],color=cmap[-2])\n# log scale for y axis\n# match it to the category learning plot\nax[1].set_yscale('log')\n\n\n\n\nax[1].set_xlabel(\"Trial\")\nax[1].set_ylabel(\"p-value\")\n# dashed grey horizontal line at .05\nax[1].axhline(.05,ls=\"--\",color=cmap[-1],lw=1)\n# remove legend\nax[1].legend_.remove()\n\nax[0].text(-.1, 1.0, string.ascii_uppercase[0], transform=ax[0].transAxes, weight='bold')\nax[1].text(-.1, 1.0, string.ascii_uppercase[1], transform=ax[1].transAxes, weight='bold')\nplt.show()\n\n\n\n\nwith mpl.rc_context(latex_context):\n    fig.savefig(join(project_root, \"figures\",\"p_values.pdf\"), bbox_inches='tight')\n\n\n\n\n\n\n\nSparse Models\n\n\nCode\nfig = plt.figure(layout=\"constrained\",figsize=(FIGWIDTH, FIGWIDTH))\nspec = fig.add_gridspec(2, )\nax0 = fig.add_subplot(spec[0])\nax0.text(0, 1.2, string.ascii_uppercase[0], transform=ax0.transAxes, weight='bold')\n\ndfs = glob.glob(join(project_root, \"data\", \"learner_behavioural\", \"category_learning\", \"*_l1_original.csv\"))\ndfs = [pd.read_csv(x) for x in dfs]\nmodel_df = pd.concat(dfs)\nmodel_df[\"nll\"] = - np.where(model_df.choice == 1, np.log(model_df.prob), np.log(1-model_df.prob))\nchance_level = - model_df.participant.nunique() * CATEGORYTRIALS * np.log(0.5)\nmodel_df = model_df.groupby(\"features\").agg({\"nll\":\"sum\"}).reset_index()\nmodel_df = model_df.sort_values(by=\"nll\",ascending=True).reset_index(drop=True)\nmodel_df[\"color\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"colour\"])\nmodel_df[\"features\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"name\"])\n\nsns.barplot(\n    data=model_df,x=\"features\",y=\"nll\",hue=\"color\",dodge=False,ax=ax0,\n    hue_order=[\"task\",\"supervised\",\"self-supervised\",\"self-supervised multimodal\",\"text\"]\n            )\nax0.legend_.remove()\nax0.axhline(chance_level,ls=\"--\",color=cmap[-1])\n# show x-axis ticks in the bars\nax0.xaxis.set_tick_params(rotation=90)\nax0.set_ylabel(\"Negative Log Likelihood\")\nax0.set_xlabel(\"\")\nax0.set_ylim(5000,8000)\nax0.set_yticks([5000,6000,7000,8000])\nax0.yaxis.set_label_coords(-0.07,.4)\n\n\n\n\nax1 = fig.add_subplot(spec[1])\nax1.text(0, 1.2, string.ascii_uppercase[1], transform=ax1.transAxes, weight='bold')\n\ndfs = glob.glob(join(project_root, \"data\", \"learner_behavioural\", \"reward_learning\", \"*_l1_original.csv\"))\ndfs = [pd.read_csv(x) for x in dfs]\nmodel_df = pd.concat(dfs)\nmodel_df[\"prob\"] = np.where(model_df.prob ==1,.99999,model_df.prob)\nmodel_df[\"nll\"] = - np.where(model_df.choice == 1, np.log(model_df.prob), np.log(1-model_df.prob))\nchance_level = - model_df.participant.nunique() * REWARDTRIALS * np.log(0.5)\nmodel_df = model_df.groupby(\"features\").agg({\"nll\":\"sum\"}).reset_index()\nmodel_df = model_df.sort_values(by=\"nll\",ascending=True).reset_index(drop=True)\nmodel_df[\"color\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"colour\"])\nmodel_df[\"features\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"name\"])\nreward_model_df = model_df\n\nsns.barplot(\n    data=model_df,x=\"features\",y=\"nll\",hue=\"color\",dodge=False,ax=ax1,\n    hue_order=[\"task\",\"supervised\",\"self-supervised\",\"self-supervised multimodal\",\"text\"]\n            )\nax1.legend_.remove()\nax1.axhline(chance_level,ls=\"--\",color=cmap[-1])\n# show x-axis ticks in the bars\nax1.xaxis.set_tick_params(rotation=90)\nax1.set_ylabel(\"Negative Log Likelihood\")\nax1.set_xlabel(\"\")\nax1.set_ylim(2500,3500)\nax1.set_yticks([2500,3000,3500])\nax1.yaxis.set_label_coords(-0.07,.4)\n\ncustom_legend_lines = [Line2D([0], [0], color=x, lw=2, path_effects=[pe.Stroke(linewidth=4, foreground=cmap[-1]), pe.Normal()]) for x in cmap[:-1]]\nhue_order = ['Task','Supervised','Self-Supervised','Self-Supervised\\nMulti-Modal','Language']\nfig.legend(custom_legend_lines, hue_order, loc='center',bbox_to_anchor=(0.54, 1),ncol=5,frameon=False)\n\nplt.show()\n\nwith mpl.rc_context(latex_context):\n    fig.savefig(join(project_root, \"figures\",\"sparse_models.pdf\"), bbox_inches='tight')\n\n\n\n\n\n\n\nPCA Models\n\n\nCode\nfig = plt.figure(layout=\"constrained\",figsize=(FIGWIDTH, FIGWIDTH))\nspec = fig.add_gridspec(2, )\nax0 = fig.add_subplot(spec[0])\nax0.text(0, 1.2, string.ascii_uppercase[0], transform=ax0.transAxes, weight='bold')\n\ndfs = glob.glob(join(project_root, \"data\", \"learner_behavioural\", \"category_learning\", \"*_l2_pca.csv\"))\ndfs = [pd.read_csv(x) for x in dfs]\nmodel_df = pd.concat(dfs)\nmodel_df[\"nll\"] = - np.where(model_df.choice == 1, np.log(model_df.prob), np.log(1-model_df.prob))\nchance_level = - model_df.participant.nunique() * CATEGORYTRIALS * np.log(0.5)\nmodel_df = model_df.groupby(\"features\").agg({\"nll\":\"sum\"}).reset_index()\nmodel_df = model_df.sort_values(by=\"nll\",ascending=True).reset_index(drop=True)\nmodel_df[\"color\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"colour\"])\nmodel_df[\"features\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"name\"])\n\nsns.barplot(\n    data=model_df,x=\"features\",y=\"nll\",hue=\"color\",dodge=False,ax=ax0,\n    hue_order=[\"task\",\"supervised\",\"self-supervised\",\"self-supervised multimodal\",\"text\"]\n            )\nax0.legend_.remove()\nax0.axhline(chance_level,ls=\"--\",color=cmap[-1])\n# show x-axis ticks in the bars\nax0.xaxis.set_tick_params(rotation=90)\nax0.set_ylabel(\"Negative Log Likelihood\")\nax0.set_xlabel(\"\")\nax0.set_ylim(5000,8000)\nax0.set_yticks([5000,6000,7000,8000])\nax0.yaxis.set_label_coords(-0.07,.4)\n\n\n\n\nax1 = fig.add_subplot(spec[1])\nax1.text(0, 1.2, string.ascii_uppercase[1], transform=ax1.transAxes, weight='bold')\n\ndfs = glob.glob(join(project_root, \"data\", \"learner_behavioural\", \"reward_learning\", \"*_l2_pca.csv\"))\ndfs = [pd.read_csv(x) for x in dfs]\nmodel_df = pd.concat(dfs)\nmodel_df[\"prob\"] = np.where(model_df.prob ==1,.99999,model_df.prob)\nmodel_df[\"nll\"] = - np.where(model_df.choice == 1, np.log(model_df.prob), np.log(1-model_df.prob))\nchance_level = - model_df.participant.nunique() * REWARDTRIALS * np.log(0.5)\nmodel_df = model_df.groupby(\"features\").agg({\"nll\":\"sum\"}).reset_index()\nmodel_df = model_df.sort_values(by=\"nll\",ascending=True).reset_index(drop=True)\nmodel_df[\"color\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"colour\"])\nmodel_df[\"features\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"name\"])\n\n\nsns.barplot(\n    data=model_df,x=\"features\",y=\"nll\",hue=\"color\",dodge=False,ax=ax1,\n    hue_order=[\"task\",\"supervised\",\"self-supervised\",\"self-supervised multimodal\",\"text\"]\n            )\nax1.legend_.remove()\nax1.axhline(chance_level,ls=\"--\",color=cmap[-1])\n# show x-axis ticks in the bars\nax1.xaxis.set_tick_params(rotation=90)\nax1.set_ylabel(\"Negative Log Likelihood\")\nax1.set_xlabel(\"\")\nax1.set_ylim(2500,3500)\nax1.set_yticks([2500,3000,3500])\nax1.yaxis.set_label_coords(-0.07,.4)\n\ncustom_legend_lines = [Line2D([0], [0], color=x, lw=2, path_effects=[pe.Stroke(linewidth=4, foreground=cmap[-1]), pe.Normal()]) for x in cmap[:-1]]\nhue_order = ['Task','Supervised','Self-Supervised','Self-Supervised\\nMulti-Modal','Language']\nfig.legend(custom_legend_lines, hue_order, loc='center',bbox_to_anchor=(0.54, 1),ncol=5,frameon=False)\n\nplt.show()\n\nwith mpl.rc_context(latex_context):\n    fig.savefig(join(project_root, \"figures\",\"pca_models.pdf\"), bbox_inches='tight')\n\n\n\n\n\n\n\nThe Effect of Dimensionality\n\n\nCode\nSINGLECOLWIDTH = 3.4252\nfig, ax = plt.subplots(1,1,figsize=(SINGLECOLWIDTH, SINGLECOLWIDTH))\n\ndfs = glob.glob(join(project_root, \"data\", \"learner_behavioural\", \"category_learning\", \"*_l2_original.csv\"))\ndfs = [pd.read_csv(x) for x in dfs]\nmodel_df = pd.concat(dfs)\nmodel_df[\"nll\"] = - np.where(model_df.choice == 1, np.log(model_df.prob), np.log(1-model_df.prob))\nchance_level = - model_df.participant.nunique() * CATEGORYTRIALS * np.log(0.5)\nmodel_df = model_df.groupby(\"features\").agg({\"nll\":\"sum\"}).reset_index()\nmodel_df = model_df.sort_values(by=\"nll\",ascending=True).reset_index(drop=True)\nmodel_df[\"color\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"colour\"])\n\ncategory_df = model_df\n\ndfs = glob.glob(join(project_root, \"data\", \"learner_behavioural\", \"reward_learning\", \"*_l2_original.csv\"))\ndfs = [pd.read_csv(x) for x in dfs]\nmodel_df = pd.concat(dfs)\nmodel_df[\"prob\"] = np.where(model_df.prob ==1,.99999,model_df.prob)\nmodel_df[\"nll\"] = - np.where(model_df.choice == 1, np.log(model_df.prob), np.log(1-model_df.prob))\nchance_level = - model_df.participant.nunique() * REWARDTRIALS * np.log(0.5)\nmodel_df = model_df.groupby(\"features\").agg({\"nll\":\"sum\"}).reset_index()\nmodel_df = model_df.sort_values(by=\"nll\",ascending=True).reset_index(drop=True)\nmodel_df[\"color\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"colour\"])\n\nreward_model_df = model_df\n\n# merge the two dataframes as new column\nmodel_df = pd.merge(category_df, reward_model_df, on=\"features\", suffixes=(\"_category\", \"_reward\"))\nmodel_df[\"nll\"] = model_df[\"nll_category\"] + model_df[\"nll_reward\"]\nmodel_df[\"color\"] = model_df[\"color_category\"]\n\nfor feat in model_df.features.unique():\n    feat_path = join(project_root, \"data\", \"features\",f\"{feat}.txt\")\n    # count the number of columns\n    with open(feat_path, \"r\") as f:\n        n_cols = len(f.readline().split())\n    model_df.loc[model_df.features == feat, \"n_features\"] = n_cols\n\nmodel_df[\"features\"] = model_df[\"features\"].apply(lambda x: plot_params[x][\"name\"])\n\nsns.scatterplot(data=model_df,x=\"n_features\",y=\"nll\",hue=\"color\",ax=ax,palette=cmap[:-2],s=50,legend=False,edgecolor=cmap[-1],\n                hue_order=[\"task\",\"supervised\",\"self-supervised\",\"self-supervised multimodal\",\"text\"])\nax.set_xlabel(\"Number of Features\")\nax.set_ylabel(\"Negative Log Likelihood\")\n\n\ncustom_legend_lines = [Line2D([0], [0], color=x, marker=\"o\",markeredgecolor=cmap[-1],linestyle=\"-\", linewidth=0) for x in cmap[:-2]]\nhue_order = ['Task','Supervised','Self-Supervised','Self-Supervised\\nMulti-Modal','Language']\nax.legend(custom_legend_lines, hue_order, loc='center',bbox_to_anchor=(.75, .2),ncol=1,frameon=True,framealpha=.8,edgecolor=cmap[-1])\n\nr, p = kendalltau(model_df.n_features, model_df.nll)\nax.text(0.75, 1, r\"$\\tau$\" +f\"= {r:.2f}, p = {p:.2f}\", horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n\n\nplt.show()\n\nwith mpl.rc_context(latex_context):\n    fig.savefig(join(project_root, \"figures\",\"representation_size.pdf\"), bbox_inches='tight')"
  },
  {
    "objectID": "bin/extract_features.html",
    "href": "bin/extract_features.html",
    "title": "Extract Features From DNNs",
    "section": "",
    "text": "Here, I extract features from various DNNs. The relevant functions are called from NaturalCogSci.feature_extractors. After each image, the extracted features are saved under the data/tempdirectory. These features are later combined in the script under the data/featuresdirectory. This is because our GPUs are not large enough.\nBelow are three scripts. The bash script calls the slurm file (this is for parallelisation on the cluster). The slurm file calls the Python script.\n#!/bin/bash\n\nmodels=$(jq -c -r 'keys_unsorted[]' \"$NATURALCOGSCI_ROOT\"/data/model_configs.json)\n\nfor model in $models; do\n    sbatch \"$NATURALCOGSCI_ROOT\"/src/sh/extract_features.slurm \\\n        -f \"$model\" \\\n        -c true\ndone\nNote that the slurm script below loads the models and runs inference using GPUs.\n#!/bin/bash -l\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --time=12:00:00\n#SBATCH --partition=gpu\n#SBATCH --mem-per-cpu=26000MB\n#SBATCH --cpus-per-task=1\n\nmodule purge\nmodule load singularity\n\nwhile getopts \":f:c:\" opt; do\n  case $opt in\n  f)\n    featurename=\"$OPTARG\"\n    ;;\n  c)\n    cached=\"$OPTARG\"\n    ;;\n  \\?)\n    echo \"Invalid option -$OPTARG\" &gt;&2\n    exit 1\n    ;;\n  esac\ndone\n\nsingularity exec --nv \"$NATURALCOGSCI_ROOT\"/NaturalCogSci.sif \\\n  python3 \"$NATURALCOGSCI_ROOT\"/nbs/bin/extract-features-script.py \\\n  --featurename \"$featurename\" \\\n  --cached \"$cached\"\n\n# Finish the script\nexit 0\nimport argparse\nimport json\nfrom os.path import join\n\nimport torch\n\nfrom NaturalCogSci.feature_extractors import extract_features\nfrom NaturalCogSci.helpers import str2bool, get_project_root\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\"--featurename\", \"-f\",nargs='+')\n    parser.add_argument(\"--cached\", \"-c\",type=str2bool)\n\n    args = parser.parse_args()\n\n    if args.featurename == \"all\":\n        project_root = get_project_root()\n        with open(join(project_root,\"data\",\"model_configs.json\")) as f:\n            features = json.load(f).keys()\n    \n    else:\n        features = args.featurename\n            \n    for feature in features:\n\n        print(f\"Extracting features for {feature}\",flush=True)\n        torch.cuda.empty_cache()\n        extract_features(feature,args.cached)"
  },
  {
    "objectID": "bin/loo_cv.html",
    "href": "bin/loo_cv.html",
    "title": "Leave-One-Trial-Out Cross Validation",
    "section": "",
    "text": "Using the predictions of the learning models, perform a loo-cv, where each trial serves once as the only observation in the test set.\nBelow are three scripts. The bash script calls the slurm file (this is for parallelisation on the cluster). The slurm file calls the R script.\n#!/bin/bash\n\nembeddings=$(jq -c -r 'keys_unsorted[]' \"$NATURALCOGSCI_ROOT\"/data/model_configs.json)\n\nfor experiment in reward_learning category_learning; do\n    for features in $embeddings; do\n        for transform in original pca; do\n            for regularisation in l1 l2; do\n\n                sbatch \"$NATURALCOGSCI_ROOT\"/nbs/bin/loo_cv.slurm \\\n                    -e $experiment -f \"$features\" -t $transform -r $regularisation\n            done\n        done\n    done\ndone\n#!/bin/bash -l\n\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --time=1-00:00:00\n#SBATCH --partition compute\n#SBATCH --mem-per-cpu=10000MB\n\nmodule purge\nmodule load singularity\n\nwhile getopts \":e:f:t:r:\" opt; do\n  case $opt in\n  e)\n    experiment=\"$OPTARG\"\n    ;;\n  f)\n    features=\"$OPTARG\"\n    ;;\n  t)\n    transform=\"$OPTARG\"\n    ;;\n  r)\n    regularisation=\"$OPTARG\"\n    ;;\n  \\?)\n    echo \"Invalid option -$OPTARG\" &gt;&2\n    exit 1\n    ;;\n  esac\ndone\n\nsingularity exec \"$NATURALCOGSCI_ROOT\"/NaturalCogSci.sif \\\n  Rscript \"$NATURALCOGSCI_ROOT\"/nbs/bin/loo-cv-script.R \\\n  \"$features\" \"$experiment\" \"$regularisation\" \"$transform\"\n\n# Finish the script\nexit 0\nlibrary(lme4)\nlibrary(tidyverse)\n\nargs &lt;- commandArgs(trailingOnly = TRUE)\nfeature &lt;- args[1]\ntask &lt;- args[2]\npenalty &lt;- args[3]\ntransform &lt;- args[4]\n\nproject_root &lt;- Sys.getenv(\"NATURALCOGSCI_ROOT\")\n\nfeature &lt;- gsub(\"/\", \"_\", feature)\n\ndf_path &lt;- file.path(\n  project_root, \"data\", \"learner_behavioural\", task,\n  sprintf(\"%s_%s_%s.csv\", feature, penalty, transform)\n)\n\n\ntemp_df &lt;- read_csv(df_path)\nif (grepl(\"category_learning\", df_path, fixed = TRUE)) {\n  temp_df &lt;- temp_df %&gt;%\n    mutate(diff = right_value)\n} else {\n  temp_df &lt;- temp_df %&gt;%\n    mutate(diff = right_value - left_value)\n}\n\nrow_no &lt;- nrow(temp_df)\npar_no &lt;- temp_df %&gt;%\n  select(participant) %&gt;%\n  n_distinct()\ntrial_no &lt;- temp_df %&gt;%\n  select(trial) %&gt;%\n  n_distinct()\n\nprob &lt;- matrix(nrow = row_no, ncol = 1)\n\npb &lt;- txtProgressBar(min = 0, max = row_no, style = 3)\n\nfor (i in 1:row_no) {\n  training &lt;- temp_df %&gt;% slice(-i)\n  test &lt;- temp_df %&gt;% slice(i)\n  # get the scaling parameters first\n  training_mean &lt;- training %&gt;%\n    pull(diff) %&gt;%\n    mean()\n  training_std &lt;- training %&gt;%\n    pull(diff) %&gt;%\n    sd()\n\n  # scale training\n  training &lt;- training %&gt;%\n    mutate(scaled_diff = (diff - training_mean) / training_std)\n\n  # scale test\n  test &lt;- test %&gt;%\n    mutate(scaled_diff = (diff - training_mean) / training_std)\n\n\n  temp_glmm &lt;- glmer(\n    choice ~ -1 + scaled_diff +\n      (-1 + scaled_diff | participant),\n    family = \"binomial\", data = training\n  )\n\n  prediction &lt;- predict(temp_glmm, newdata = test, type = \"response\")\n  prob[i, 1] &lt;- prediction\n\n\n  setTxtProgressBar(pb, i)\n}\n\ntemp_df &lt;- temp_df %&gt;% select(-diff)\ntemp_df &lt;- temp_df %&gt;% mutate(prob = prob)\nclose(pb)\n\n\nwrite.csv(temp_df, df_path, row.names = FALSE)"
  },
  {
    "objectID": "bin/rsa.html",
    "href": "bin/rsa.html",
    "title": "RSA Scripts",
    "section": "",
    "text": "Here, I compute the CKA between:\n\nTask embedding and all other representations.\nAll CLIP representations and every other representation\n\nBelow are three scripts. The bash script calls the slurm file (this is for parallelisation on the cluster). The slurm file calls the Python script.\n#!/bin/bash\n\nfor target in task clip_RN50 clip_RN101 clip_RN50x4 clip_ViT-B_16 clip_ViT-B_32 clip_ViT-L_14; do\n    sbatch \"$NATURALCOGSCI_ROOT\"/nbs/bin/cka.slurm \\\n        -f all -t $target\ndone\n#!/bin/bash -l\n\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --time=5-00:00:00\n#SBATCH --partition=compute\n#SBATCH --mem-per-cpu=20000MB\n#SBATCH --cpus-per-task=1\n\nmodule purge\nmodule load singularity\n\nwhile getopts \":f:t:\" opt; do\n  case $opt in\n  f)\n    features=\"$OPTARG\"\n    ;;\n  t)\n    target=\"$OPTARG\"\n    ;;\n  \\?)\n    echo \"Invalid option -$OPTARG\" &gt;&2\n    exit 1\n    ;;\n  esac\ndone\n\nsingularity exec \"$NATURALCOGSCI_ROOT\"/NaturalCogSci.sif \\\n  python3 \"$NATURALCOGSCI_ROOT\"/nbs/bin/cka-script.py \\\n  -f \"$features\" -t \"$target\"\n\n# Finish the script\nexit 0\nimport os\nfrom os.path import join\nimport glob\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nfrom NaturalCogSci.helpers import get_project_root\nfrom NaturalCogSci.rsatools import cka\n\n\ndef main(args):\n\n    project_root = get_project_root()\n    if args.features == \"all\":\n        feature_list = glob.glob(\n            join(project_root, \"data\", \"features\", \"*.txt\")\n        )\n        feature_list.remove(join(project_root, \"data\", \"features\", \"file_names.txt\"))\n    else:\n        feature_list = [join(project_root, \"data\", \"features\", f\"{args.features}.txt\")]\n\n    df_feature_list = []\n    df_cka_list = [] \n    for feature in tqdm(feature_list):\n        cka_value = cka(X=np.loadtxt(feature),\n                    Y=np.loadtxt(\n            join(project_root, \"data\", \"features\", f\"{args.target}.txt\")))\n        df_feature_list.append(feature.split(os.sep)[-1].split(\".txt\")[0])\n        df_cka_list.append(cka_value)\n\n\n\n\n    df = pd.DataFrame({\"feature\": df_feature_list, \"cka\": df_cka_list})\n    file_name = join(project_root, \"data\", \"cka\", f\"target_{args.target}.csv\")\n    df.to_csv(\n        file_name,\n        index=False)\n    \n\nif __name__ == \"__main__\":\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--features\", \"-f\")\n    parser.add_argument(\"--target\", \"-t\")\n\n    args = parser.parse_args()\n\n    main(args)"
  },
  {
    "objectID": "bin/run_learners.html",
    "href": "bin/run_learners.html",
    "title": "Running Learning Models",
    "section": "",
    "text": "Here, I run the learning models written in NaturalCogSci.learners. All the combinations of the following are ran and saved:\n\nAll representations (50)\nL1 and L2 regularised models\nOriginal and PCA derived features\n\nBelow are three scripts. The bash script calls the slurm file (this is for parallelisation on the cluster). The slurm file calls the Python script.\n#!/bin/bash\n\nembeddings=$(jq -c -r 'keys_unsorted[]' \"$NATURALCOGSCI_ROOT\"/data/model_configs.json)\n\nfor experiment in reward_learning category_learning; do\n    for features in $embeddings; do\n        for transform in original pca; do\n            for regularisation in l1 l2; do\n\n                sbatch \"$NATURALCOGSCI_ROOT\"/nbs/bin/run_learners.slurm \\\n                    -e $experiment -f \"$features\" -t $transform -r $regularisation\n            done\n        done\n    done\ndone\n#!/bin/bash -l\n\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --time=12:00:00\n#SBATCH --partition=compute\n#SBATCH --mem-per-cpu=20000MB\n#SBATCH --cpus-per-task=1\n\nmodule purge\nmodule load singularity\n\nwhile getopts \":e:f:t:r:\" opt; do\n  case $opt in\n  e)\n    experiment=\"$OPTARG\"\n    ;;\n  f)\n    feature=\"$OPTARG\"\n    ;;\n  t)\n    transform=\"$OPTARG\"\n    ;;\n  r)\n    regularisation=\"$OPTARG\"\n    ;;\n  \\?)\n    echo \"Invalid option -$OPTARG\" &gt;&2\n    exit 1\n    ;;\n  esac\ndone\n\nsingularity exec \"$NATURALCOGSCI_ROOT\"/NaturalCogSci.sif \\\n  python3 \"$NATURALCOGSCI_ROOT\"/nbs/bin/run-learners-script.py \\\n  --experiment \"$experiment\" \\\n  --features \"$feature\" \\\n  --transform \"$transform\" \\\n  --regularisation \"$regularisation\"\n\n# Finish the script\nexit 0\nimport argparse\nimport tqdm\nimport os\nfrom os.path import join, isfile\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import BayesianRidge, ARDRegression, LogisticRegression\nfrom sklearn.decomposition import PCA\n\nfrom NaturalCogSci.helpers import get_project_root, prepare_training\nfrom NaturalCogSci.learners import RewardLearner, CategoryLearner\n\n\ndef fit_regulariser(penalty_type, X, y):\n    best_score = 0\n    best_alpha = 1\n    for alpha in [\n        0.0001,\n        0.0005,\n        0.001,\n        0.005,\n        0.01,\n        0.05,\n        0.1,\n        0.5,\n        1,\n        1.5,\n        2,\n        3,\n        4,\n        5,\n        10,\n        15,\n        20,\n    ]:\n        category_learner = CategoryLearner(\n            LogisticRegression(\n                penalty=penalty_type, C=alpha, max_iter=5000, solver=\"liblinear\"\n            )\n        )\n        category_learner.fit(X, y)\n        if category_learner.estimator.score(X, y) &gt; best_score:\n            best_score = category_learner.estimator.score(X, y)\n            best_alpha = alpha\n\n    return best_alpha\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\"--experiment\", \"-e\")\n    parser.add_argument(\"--features\", \"-f\")\n    parser.add_argument(\"--transform\", \"-t\")\n    parser.add_argument(\"--regularisation\", \"-r\")\n\n    args = parser.parse_args()\n    experiment = args.experiment\n    features = args.features\n    transform = args.transform\n    regularisation = args.regularisation\n\n\n    features = features.replace(\"/\", \"_\")\n    print(experiment, features, transform, regularisation,flush=True)\n\n    project_root = get_project_root()\n    save_file_name = join(\n        project_root,\n        \"data\",\n        \"learner_behavioural\",\n        experiment,\n        f\"{features}_{regularisation}_{transform}.csv\",\n    )\n\n    if isfile(save_file_name):\n        print(\"file already exists!\")\n        exit()\n    df = pd.read_csv(\n        join(project_root, \"data\", \"human_behavioural\", experiment, \"above_chance.csv\")\n    )\n\n    participants = df.participant.unique()\n\n    model_dfs = []\n    for participant in tqdm.tqdm(participants):\n        cond_file = df[df.participant == participant][\"cond_file\"].unique()[0]\n        X, y = prepare_training(experiment, features, cond_file)\n\n        N_FEATURES = 49  # this is the number of features in the task\n        N_TRIALS = 60\n        N_OPTIONS = 2\n\n        if experiment == \"reward_learning\":\n            estimator = BayesianRidge() if regularisation == \"l2\" else ARDRegression()\n            learner = RewardLearner(estimator=estimator)\n            if transform == \"pca\":\n                X = X.reshape(N_TRIALS * N_OPTIONS, -1)\n                X = PCA(n_components=N_FEATURES).fit_transform(X)\n                X = X.reshape(N_TRIALS, N_OPTIONS, -1)\n            learner.fit(X, y)\n\n        else:\n            penalty_coef = fit_regulariser(regularisation, X, y)\n            learner = CategoryLearner(\n                estimator=LogisticRegression(\n                    penalty=regularisation,\n                    C=penalty_coef,\n                    max_iter=5000,\n                    solver=\"liblinear\",\n                )\n            )\n\n            X = (\n                PCA(n_components=N_FEATURES).fit_transform(X)\n                if transform == \"pca\"\n                else X\n            )\n            learner.fit(X, y)\n\n        model_df = df[df.participant == participant].reset_index(drop=True)\n        model_df[\"left_value\"] = learner.values[:, 0]\n        model_df[\"right_value\"] = learner.values[:, 1]\n        model_df[\"features\"] = features\n        model_df[\"transform\"] = transform\n        model_df[\"penalty\"] = regularisation\n\n        model_dfs.append(model_df)\n\n    large_model_df = pd.concat(model_dfs)\n    large_model_df.to_csv(\n        save_file_name,\n        index=False,\n    )\n\n    print(\"Done!\", flush=True)"
  },
  {
    "objectID": "bin/preprocess.html",
    "href": "bin/preprocess.html",
    "title": "Data Preprocessing Script",
    "section": "",
    "text": "Here, I call functions from NaturalCogSci.helpers to assemble jsons into anonymised csv files.\nSince I don’t share the original json and csv files this is not relevant for anyone but me really.\nfrom NaturalCogSci.helpers import parse_reward_data, parse_category_data\n\nif __name__ == \"__main__\":\n    parse_reward_data()\n    parse_category_data()"
  },
  {
    "objectID": "rsatools.html",
    "href": "rsatools.html",
    "title": "RSA Tools",
    "section": "",
    "text": "Functions for representational similarity analyses\n\n\n\nimport numpy as np\n\nfrom NaturalCogSci.helpers import get_project_root\n\n\n\nCode\ndef cka(X: np.ndarray, # Representations of the first set of samples.\n        Y:np.ndarray # Representations of the second set of samples.\n        ) -&gt; float: # The linear CKA between X and Y.\n    \"\"\"\n    Compute the linear CKA between two matrices X and Y.\n\n    [link to the paper](https://arxiv.org/abs/1905.00414)\n\n    taken from Patrick Mineault's implementation of CKA as is.\n\n    [link to original implementation](https://goodresearch.dev/cka.html)\n\n    Matrices should be observations by features.\n\n    \"\"\"\n    # Implements linear CKA as in Kornblith et al. (2019)\n    X = X.copy()\n    Y = Y.copy()\n\n    # Center X and Y\n    X -= X.mean(axis=0)\n    Y -= Y.mean(axis=0)\n\n    # Calculate CKA\n    XTX = X.T.dot(X)\n    YTY = Y.T.dot(Y)\n    YTX = Y.T.dot(X)\n\n    return (YTX ** 2).sum() / np.sqrt((XTX ** 2).sum() * (YTY ** 2).sum())\n\n\n\nsource\n\ncka\n\n cka (X:numpy.ndarray, Y:numpy.ndarray)\n\nCompute the linear CKA between two matrices X and Y.\nlink to the paper\ntaken from Patrick Mineault’s implementation of CKA as is.\nlink to original implementation\nMatrices should be observations by features.\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\nRepresentations of the first set of samples.\n\n\nY\nndarray\nRepresentations of the second set of samples.\n\n\nReturns\nfloat\nThe linear CKA between X and Y."
  }
]