{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "> All the helper functions used in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "# | code-fold: false\n",
    "import json\n",
    "import argparse\n",
    "import string\n",
    "import glob\n",
    "import os\n",
    "from os.path import join\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "\n",
    "def get_project_root() -> str:  # project root\n",
    "    \"\"\"\n",
    "    Return project root based on device.\n",
    "\n",
    "    Reads the NATURALCOGSCI_ROOT environment variable\n",
    "    \"\"\"\n",
    "\n",
    "    return os.getenv(\"NATURALCOGSCI_ROOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def prepare_training(\n",
    "    task: str,  # 'reward_learning' or 'category_learning'\n",
    "    features: str,  # which embedding to use. must match the saved .txt files\n",
    "    cond_file: int,  # number of the condtion file to prepare arrays for\n",
    ") -> Tuple[np.ndarray, np.ndarray]:  # X,y arrays\n",
    "    \"\"\"\n",
    "    Prepares the observations and the target values to train models on,\n",
    "    for the given condition file and the given task. The returned arrays\n",
    "    have the shapes shown in the tables below.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    tasks = [\"reward_learning\", \"category_learning\"]\n",
    "    assert task in tasks, f\"{task} must be one of {tasks}\"\n",
    "\n",
    "    project_root = get_project_root()\n",
    "\n",
    "    df = pd.read_csv(join(project_root, \"data\", \"human_behavioural\", task, \"all.csv\"))\n",
    "    df = df[df.cond_file == cond_file].reset_index(drop=True)\n",
    "\n",
    "    with open(join(project_root, \"data\", \"features\", \"file_names.txt\"), \"r\") as f:\n",
    "        file_names = f.read()\n",
    "\n",
    "    file_names = file_names.split(\"\\n\")[:-1]\n",
    "    file_names = [file_name.split(\"NaturalCogSci/\")[1] for file_name in file_names]\n",
    "    embedding = np.loadtxt(join(project_root, \"data\", \"features\", f\"{features}.txt\"))\n",
    "    if task == \"reward_learning\":\n",
    "        TRIALS = 60\n",
    "        OPTIONS = 2\n",
    "\n",
    "        left_stimuli = df.left_image.to_list()\n",
    "        right_stimuli = df.right_image.to_list()\n",
    "\n",
    "        left_stimuli = [\n",
    "            file_names.index(left_stimulus) for left_stimulus in left_stimuli\n",
    "        ]\n",
    "        right_stimuli = [\n",
    "            file_names.index(right_stimulus) for right_stimulus in right_stimuli\n",
    "        ]\n",
    "\n",
    "        X = np.zeros((TRIALS, OPTIONS, embedding.shape[1]))\n",
    "        X[:, 0, :] = embedding[left_stimuli, :]\n",
    "        X[:, 1, :] = embedding[right_stimuli, :]\n",
    "\n",
    "        y = np.zeros((TRIALS, OPTIONS))\n",
    "        y[:, 0] = df.left_reward.to_list()\n",
    "        y[:, 1] = df.right_reward.to_list()\n",
    "\n",
    "    elif task == \"category_learning\":\n",
    "        TRIALS = 120\n",
    "\n",
    "        stimuli = df.image.to_list()[:TRIALS]\n",
    "\n",
    "        stimuli = [file_names.index(stimulus) for stimulus in stimuli]\n",
    "\n",
    "        X = np.zeros((TRIALS, embedding.shape[1]))\n",
    "        X[:] = embedding[stimuli, :]\n",
    "        y = df.true_category_binary.to_numpy()[:TRIALS]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Category Learning***\n",
    "\n",
    "| Array | Dim 1 | Dim 2  |\n",
    "|---|-------|-------------------|\n",
    "| X | trial | features |\n",
    "| y | trial | |\n",
    "\n",
    "***Reward Learning***\n",
    "\n",
    "| Array | Dim 1 | Dim 2  | Dim 3 |\n",
    "|---|-------|-------------------|----------|\n",
    "| X | trial | options (left==0) | features |\n",
    "| y | trial | options (left==0) |          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def str2bool(\n",
    "    v: str | bool,  # input from the command line\n",
    ") -> bool:  # Python Boolean\n",
    "    \"\"\"\n",
    "    Used to parse boolean command line arguments for Python.\n",
    "    \"\"\"\n",
    "    if v == \"true\":\n",
    "        return True\n",
    "    elif v == \"false\":\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError(\"Boolean value expected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def id_generator(\n",
    "    size: int = 10,  # length of ID\n",
    "    chars: str = string.ascii_uppercase + string.digits,  # characters to use\n",
    ") -> str:  # unique ID\n",
    "    \"\"\"\n",
    "    Used to generate IDs for participants. This is to hide their Prolific IDs.\n",
    "    \"\"\"\n",
    "    return \"\".join(np.random.choice(list(chars), size=size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def parse_reward_data() -> None:\n",
    "    \"\"\"\n",
    "    Read and parse json data and condition files of reward learning into pandas dataframes.\n",
    "\n",
    "    Make 2 dataframes:\n",
    "\n",
    "    1. all_df: includes all participants\n",
    "    2. keep_df: includes only those with above 50% accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    project_root = get_project_root()\n",
    "    BASE_PAY = 2.0\n",
    "    TRIAL_NO = 60\n",
    "\n",
    "    beh_files = glob.glob(\n",
    "        join(project_root, \"experiments\", \"reward_learning\", \"data\", \"*json\")\n",
    "    )\n",
    "    df_list = []\n",
    "\n",
    "    for beh_file_path in beh_files:\n",
    "        with open(beh_file_path) as f:\n",
    "            beh_file = json.load(f)\n",
    "\n",
    "        beh_file_no = os.path.splitext(os.path.basename(beh_file_path))[0]\n",
    "\n",
    "        with open(\n",
    "            join(\n",
    "                project_root,\n",
    "                \"experiments\",\n",
    "                \"reward_learning\",\n",
    "                \"condition_files\",\n",
    "                f\"{beh_file_no}.json\",\n",
    "            )\n",
    "        ) as f:\n",
    "            cond_file = json.load(f)\n",
    "\n",
    "        par_df = pd.DataFrame(\n",
    "            {\n",
    "                \"left_image\": list(cond_file[\"arm_0_image\"].values()),\n",
    "                \"right_image\": list(cond_file[\"arm_1_image\"].values()),\n",
    "                \"dimension\": list(cond_file[\"reward_dimension\"].values()),\n",
    "                \"left_reward\": list(cond_file[\"arm_0_reward\"].values()),\n",
    "                \"right_reward\": list(cond_file[\"arm_1_reward\"].values()),\n",
    "                \"max_reward\": list(cond_file[\"max_reward\"].values()),\n",
    "                \"min_reward\": list(cond_file[\"min_reward\"].values()),\n",
    "                \"choice\": beh_file[\"choices\"],\n",
    "                \"reward_received\": beh_file[\"points\"],\n",
    "                \"cond_file\": beh_file_no,\n",
    "                \"trial\": range(TRIAL_NO),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        par_df[\"bonus_payment\"] = float(beh_file[\"money\"]) - BASE_PAY\n",
    "        par_df[\"include\"] = np.where(beh_file[\"include\"] == \"yes\", 1, 0)\n",
    "        par_df[\"participant\"] = id_generator()\n",
    "        par_df[\"regret\"] = par_df[\"max_reward\"] - par_df[\"reward_received\"]\n",
    "        par_df[\"chance_regret\"] = (par_df[\"max_reward\"] - par_df[\"min_reward\"]) / 2\n",
    "        par_df[\"correct\"] = np.where(par_df.regret == 0, 1, 0)\n",
    "        df_list.append(par_df)\n",
    "\n",
    "    all_df = pd.concat(df_list)\n",
    "    filter_chance(all_df, \"reward_learning\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def parse_category_data() -> None:\n",
    "    \"\"\"\n",
    "    Read and parse behavioural csv files of category learning into pandas dataframes.\n",
    "\n",
    "    Make 2 dataframes:\n",
    "    1. all_df: includes all participants\n",
    "    2. keep_df: includes only those with above 50% accuracy\n",
    "    \"\"\"\n",
    "    BASE_PAY = 1.5\n",
    "    TRIAL_NO = 120\n",
    "\n",
    "    project_root = get_project_root()\n",
    "\n",
    "    beh_files = glob.glob(\n",
    "        join(project_root, \"experiments\", \"category_learning\", \"data\", \"task_*.csv\")\n",
    "    )\n",
    "    df_list = []\n",
    "\n",
    "    for beh_file in beh_files:\n",
    "        df = pd.read_csv(beh_file)\n",
    "        trial_df = df[df.trial_type == \"image-keyboard-response\"].reset_index(drop=True)\n",
    "\n",
    "        par_df = pd.DataFrame(\n",
    "            {\n",
    "                \"image\": trial_df.stimulus.to_list(),\n",
    "                \"choice\": np.where(trial_df.response == \"j\", 1, 0),\n",
    "                \"true_category_name\": trial_df.trueCategory,\n",
    "                \"true_category_binary\": np.where(\n",
    "                    trial_df.trueCategory == \"Julty\", 1, 0\n",
    "                ),\n",
    "                \"correct\": trial_df.correct,\n",
    "                \"cond_file\": trial_df.cond_file_no,\n",
    "                \"participant\": id_generator(),\n",
    "                \"include\": np.where(\n",
    "                    json.loads((df.tail(1)[\"response\"]).values[0])[\"include\"] == \"Yes\",\n",
    "                    1,\n",
    "                    0,\n",
    "                ),\n",
    "                \"bonus_payment\": np.round(float(df.tail(1).current_pay) - BASE_PAY, 2),\n",
    "                \"dimension\": (trial_df.cond_file_no - 1) % 3,\n",
    "                \"trial\": range(TRIAL_NO),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        df_list.append(par_df)\n",
    "\n",
    "    all_df = pd.concat(df_list)\n",
    "    filter_chance(all_df, \"category_learning\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def filter_chance(\n",
    "    df: pd.DataFrame,  # dataframe to filter\n",
    "    task: str,  # 'reward_learning' or 'category_learning'\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Take large behavioural df, and make two copies:\n",
    "\n",
    "    1.Dataframe as is\n",
    "    2. Dataframe with $p(correct) > .5$ & those who said their data should be included\n",
    "\n",
    "    Write these on the disk.\n",
    "    \"\"\"\n",
    "\n",
    "    allowed_tasks = [\"reward_learning\", \"category_learning\"]\n",
    "    assert task in allowed_tasks, f\"{task} not in {allowed_tasks}\"\n",
    "\n",
    "    project_root = get_project_root()\n",
    "    df.to_csv(\n",
    "        join(project_root, \"data\", \"human_behavioural\", task, \"all.csv\"),\n",
    "        index=False,\n",
    "    )\n",
    "    accuracy_df = df.groupby([\"participant\", \"include\"], as_index=False)[\n",
    "        \"correct\"\n",
    "    ].mean()\n",
    "    keep_participants = accuracy_df[\n",
    "        (accuracy_df.correct > 0.5) & (accuracy_df.include == True)\n",
    "    ].participant.to_list()\n",
    "    keep_df = df[df.participant.isin(keep_participants)].reset_index(drop=True)\n",
    "\n",
    "    keep_df.to_csv(\n",
    "        join(project_root, \"data\", \"human_behavioural\", task, \"above_chance.csv\"),\n",
    "        index=False,\n",
    "    )\n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
